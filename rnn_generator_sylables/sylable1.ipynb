{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objbrowser import browse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer 2.0.3 2018-04-19 (macOS i386)\n",
      "For Korrida database, spellchecker and hyphenator copyright (C) 1993-2018 Wojciech Czarnowski\n",
      "For Stemmer copyright (C) 2018 Krzysztof Wolk and Wojciech Czarnowski\n",
      "Wojciech Czarnowski: wojtek.czarnowski@gmail.com, +48(608)202-272\n",
      "Krzysztof Wolk: krz.wolk@gmail.com, +48(606)918-623\n",
      "\n",
      "Usage: stemmer options\n",
      "\n",
      "Options:\n",
      "-v, --verbose\n",
      "--version\n",
      "-s number, --stem=number\n",
      "-d file or --dict=<file.dic>\n",
      "-i file or --file_in=<file>\n",
      "-o file or --file_out=<file>\n",
      "-l file or --log=<file>\n",
      "-e file or --exclude=<file>\n",
      "--stem_delim=\"string\"\n",
      "--code_delim=\"string\"\n",
      "--divide_after=number\n",
      "\n",
      "Stemming options:\n",
      "  1 stem \"nie\" prefix\n",
      "  2 stem extra prefixes\n",
      "  4 stem prefixes in root\n",
      "  8 stem in suffix\n",
      "\n",
      "POS options:\n",
      " 16 output POS and inflection group\n",
      " 32 output additional POS info\n",
      "\n",
      "Output Korrida codes:\n",
      " 64 group code\n",
      "128 base suffix codes\n",
      "256 suffix code\n",
      "\n",
      "Division options:\n",
      " 512 divide words\n",
      "1024 divide with dictionary\n",
      "2048 divide algorithmically\n",
      "4096 divide unknown words\n",
      "\n",
      "Using 512 division option turns off stemming.\n",
      "\n",
      "Defaults:\n",
      "- stem delimiter: \"++ --\"\n",
      "- code delimiter: \"@@\"\n",
      "- options: 1+2\n",
      "- divide after 1 character\n",
      "\n",
      "Sample sets of options:\n",
      "3=1+2          (stem more words)\n",
      "15=1+2+3+4+8   (stem more words and in roots and suffixes)\n",
      "320=64+256     (output old Korrida codes)\n",
      "195=1+2+64+128 (stem more words, output new Korrida codes)\n",
      "147=1+2+16+128 (stem more words, output POS and base suffix codes)\n",
      "7683=1+2+512+1024+2048+4096 (divide (more) words with dictionary, then algorithmically and also unknown words)\n"
     ]
    }
   ],
   "source": [
    "!bin/stemmer.macos -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataset_path = Path('data/rnn_generator'); dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1144\n",
      "drwxr-xr-x  5 wcz  staff   160B Apr 30 13:56 \u001b[34m.\u001b[m\u001b[m/\n",
      "drwxr-xr-x  4 wcz  staff   128B Apr 30 13:27 \u001b[34m..\u001b[m\u001b[m/\n",
      "-rw-r--r--  1 wcz  staff   313K Apr 30 13:56 pan_tadeusz.syl1.txt\n",
      "-rw-rw-rw-@ 1 wcz  staff   218K Apr 23 19:58 pan_tadeusz.txt\n",
      "drwxr-xr-x  2 wcz  staff    64B Apr 30 13:27 \u001b[34mtmp\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls -lah $dataset_path/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hyphenated corpus\n",
    "# cleanup and tokenize later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_corpus_char = dataset_path/'pan_tadeusz.txt'\n",
    "fn_corpus_syl = dataset_path/'pan_tadeusz.syl1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffKSIĘGA PIÉRWSZA.\\n\\n\\n\\n\\nGOSPODARSTWO.\\n\\n\\nTREŚĆ.\\n\\n    Powrot panicza -- Spotkanie się piérwsze w pokoiku, drugie u\\n    stołu -- Ważna Sędziego nauka o grzeczności -- Podkomorzego uwagi\\n    polityczne nad modami -- Początek sporu o Kusego i Sokoła -- Żale\\n    Wojskiego -- Ostatni Woźny Trybunału -- Rzut oka na ówczesny stan\\n    polityczny Litwy i Europy.\\n\\n\\n  Litwo! Ojczyzno moja! ty jesteś jak zdrowie;\\nIle cię trzeba cenić, ten tylko się dowie\\nKto cię stracił. Dziś piękność twą w całéj ozdobie\\nWidzę '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_char = fn_corpus_char.open('r').read(); corpus_char[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer 2.0.3 2018-04-19 (macOS i386)\n",
      "For Korrida database, spellchecker and hyphenator copyright (C) 1993-2018 Wojciech Czarnowski\n",
      "For Stemmer copyright (C) 2018 Krzysztof Wolk and Wojciech Czarnowski\n",
      "Wojciech Czarnowski: wojtek.czarnowski@gmail.com, +48(608)202-272\n",
      "Krzysztof Wolk: krz.wolk@gmail.com, +48(606)918-623\n",
      "\n",
      "Dictionary: \"bin/stemmer2.dic\"\n",
      "Input file: \"data/rnn_generator/pan_tadeusz.txt\"\n",
      "Output file: \"data/rnn_generator/pan_tadeusz.syl1.txt\"\n",
      "Stem number: \"7683\"\n",
      "\n",
      "Stemming options:\n",
      "  StemNiePrefix     : Yes\n",
      "  StemExtraPrefixes : Yes\n",
      "  StemPrefixesInRoot: No\n",
      "\n",
      "Syllable division options:\n",
      "  DivideWords          : Yes\n",
      "  DivideWithDictionary : Yes\n",
      "  DivideAlgorithmically: Yes\n",
      "  DivideUknkownWords   : Yes\n",
      "  divideAfterChar      : 1\n",
      "\n",
      "Stemming formatting options:\n",
      "  StemInSuffix       : No\n",
      "  ShowPOSInfo        : No\n",
      "  ShowExtraPOSInfo   : No\n",
      "\n",
      "  ShowGroupCode      : No\n",
      "  ShowBaseSuffixCodes: No\n",
      "  ShowSuffixCode     : No\n",
      "\n",
      "  stemDelimiterStr   : \"++ --\"\n",
      "  codeDelimiterStr   : \"@@\"\n",
      "\n",
      "StemFile(fileInPath: \"data/rnn_generator/pan_tadeusz.txt\", fileOutPath: \"data/rnn_generator/pan_tadeusz.syl1.txt\")\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!bin/stemmer.macos -s 7683 -v -d bin/stemmer2.dic -i $fn_corpus_char -o $fn_corpus_syl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KSIĘ++ --GA PIÉ++ --RWSZA.\\n\\n\\n\\n\\nGO++ --S++ --PO++ --DAR++ --STWO.\\n\\n\\nTREŚĆ.\\n\\n    Po++ --wrot pa++ --ni++ --cza -- Spot++ --ka++ --nie się pié++ --rwsze w po++ --koi++ --ku, dru++ --gie u\\n    sto++ --łu -- Waż++ --na Sę++ --dzie++ --go na++ --u++ --ka o grze++ --cz++ --no++ --ści -- Pod++ --ko++ --mo++ --rze++ --go u++ --wa++ --gi\\n    po++ --li++ --ty++ --cz++ --ne nad mo++ --da++ --mi -- Po++ --czą++ --tek spo++ --ru o Ku++ --se++ --go i So++ --ko++ --ła -- Ża++ --le\\n    Woj++ --skie++ --go -- O++'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load hyphenated corpus\n",
    "# split into tokens\n",
    "# create set of tokens\n",
    "corpus_syl = fn_corpus_syl.open('r').read(); corpus_syl[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 2.9MB/s \n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /Users/wcz/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/wcz/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /Users/wcz/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KSIĘ++ --GA PIÉ++ --RWSZA.\\n\\n\\n\\n\\nGO++ --S++ --PO++ --DAR++ --STWO.\\n\\n\\nTREŚĆ.\\n\\n    Po++ --wrot pa++ --ni++ --cza -- Spot++ --ka++ --nie się pié++ --rwsze w po++ --koi++ --ku, dru++ --gie u\\n    sto++ --łu -- Waż++ --na Sę++ --dzie++ --go na++ --u++ --ka o grze++ --cz++ --no++ --ści -- Pod++ --ko++ --mo++ --rze++ --go u++ --wa++ --gi\\n    po++ --li++ --ty++ --cz++ --ne nad mo++ --da++ --mi -- Po++ --czą++ --tek spo++ --ru o Ku++ --se++ --go i So++ --ko++ --ła -- Ża++ --le\\n    Woj++ --skie++ --go -- O++'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_syl[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from fastai/text.py\n",
    "import re, string\n",
    "# remove +,- chars from punctuation set to keep sylables e.g.'--PO++' intact\n",
    "punctuation=re.sub('(\\+,\\-)', '', string.punctuation)\n",
    "re_tok = re.compile(f'([{punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffKSIĘGA', 'PIÉRWSZA', '.', 'GOSPODARSTWO', '.', 'TREŚĆ', '.', 'Powrot', 'panicza', '--', 'Spotkanie', 'się', 'piérwsze', 'w', 'pokoiku,', 'drugie', 'u', 'stołu', '--', 'Ważna', 'Sędziego', 'nauka', 'o', 'grzeczności', '--', 'Podkomorzego', 'uwagi', 'polityczne', 'nad']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(corpus_char[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KSIĘ++', '--GA', 'PIÉ++', '--RWSZA', '.', 'GO++', '--S++', '--PO++', '--DAR++', '--STWO', '.', 'TREŚĆ', '.', 'Po++', '--wrot', 'pa++', '--ni']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(corpus_syl[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['KSIĘ++', '--GA', 'PIÉ++', '--RWSZA', '.', 'GO++', '--S++', '--PO++'], 64414)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_syl_tok=tokenize(corpus_syl); corpus_syl_tok[:8], len(corpus_syl_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6494 ['!', '\"', '%', \"'\", '(', ')', ',', '--', '--CIA', '--DAR++', '--GA', '--GI', '--KA', '--LO++', '--MA++', '--MEK', '--MIZ++', '--NIA', '--PO++', '--RWSZA', '--S++', '--STWO', '--TA', '--TY++', '--WY', '--a++', '--aczéj', '--ał,', '--b++', '--ba', '--ba++', '--ba,', '--bach', '--baj++', '--bak', '--bak,', '--ban', '--ban++', '--bar++', '--barz,', '--baw', '--baw++', '--bał', '--baż', '--bcem', '--bcem,', '--be++', '--bek', '--bel', '--bel++', '--belg', '--bem', '--bem,', '--ber++', '--bez++', '--beł', '--bi', '--bi++', '--bi,', '--bia', '--bia++', '--bia,', '--biad', '--biad,', '--biar++', '--biać,', '--biał', '--bic', '--bie', '--bie++', '--bie,', '--biec', '--biedz', '--bieg++', '--biegł', '--biegł,', '--biem', '--bier++', '--biet++', '--biet,', '--bieć', '--bień++', '--bij++', '--bik,', '--bim', '--bim,', '--bin', '--bin++', '--bio', '--bio++', '--bio,', '--bior', '--bios', '--bios,', '--bis++', '--bisz', '--bit++', '--biu', '--biu,', '--biw++', '--bié++', '--biór', '--biór,', '--biów', '--bią', '--bią++', '--bią,', '--biąc', '--bić', '--bić,', '--bię', '--bię,', '--bił', '--bił++', '--bił,', '--bla++', '--blad++', '--bled++', '--bli++', '--blis++', '--bliż++', '--bliżéj', '--blu', '--bnie,', '--bnych', '--bną', '--bo', '--bo++', '--bo,', '--bo-bra++', '--boc++', '--boj++', '--bok', '--bom', '--bom,', '--bor', '--bor++', '--bor,', '--boszcz', '--boszcz,', '--bot++', '--boż++', '--br++', '--bra++', '--braw++', '--brać', '--brał', '--brał,', '--bre', '--bre++']\n"
     ]
    }
   ],
   "source": [
    "tokens=sorted(list(set(corpus_syl_tok))); print(len(tokens), tokens[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
