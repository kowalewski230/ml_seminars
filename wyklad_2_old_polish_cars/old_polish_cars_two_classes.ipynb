{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "old_polish_cars_two_classes.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eTmIFSt2CzHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Klasyfikacja obrazu za pomocą konwolucyjnych sieci neuronowych "
      ]
    },
    {
      "metadata": {
        "id": "BbPrpvQF2QKr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wykorzystamy konwolucyjne sieci neuronowe (ang. convolutional neural networks - CNNs), by nauczyć nasz komputer jak widzieć - a jest to coś, co jest możliwe jedynie dzięki głębokiemu uczeniu (ang. deep learning)."
      ]
    },
    {
      "metadata": {
        "id": "k1InJDsgCzH1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wprowadzenie do zadania \"Old Polish Cars\""
      ]
    },
    {
      "metadata": {
        "id": "eTDVyOHFCzH3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Spróbujemy stworzyć model, który pozwoli rozróżnić dwie marki starych polskich samochodów. Dostępne jest 2400 oznakowanych zdjęć samochodów do trenowania i 270 w zestawie testowym, które musimy spróbować oznakować."
      ]
    },
    {
      "metadata": {
        "id": "wSK7Sy_RCzH4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Umieść je na górze każdego notatnika, aby uzyskać automatyczne ponowne ładowanie\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "#matplotlib setup\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import matplotlib.style\n",
        "import matplotlib as mpl\n",
        "mpl.style.use('default')\n",
        "mpl.style.use('seaborn-ticks')\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pathlib import Path\n",
        "import shutil as sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kK1Bq_0-CzH9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tutaj importujemy niezbędne biblioteki, do czego konkretnie które służą dowiemy się podczas kursu (http://course.fast.ai)."
      ]
    },
    {
      "metadata": {
        "id": "FItIz0RbCzIB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ten plik zawiera wszystkie główne biblioteki zewnętrzne, których użyjemy.\n",
        "from fastai.imports import *\n",
        "\n",
        "from fastai.transforms import *\n",
        "from fastai.conv_learner import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.sgdr import *\n",
        "from fastai.plots import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hj-vw5MgCzID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`PATH` jest ścieżką do twoich danych - jeśli wykorzystasz zalecaną metodę konfiguracji tej lekcji, nie będziesz musiał tego zmieniać. `sz` to rozmiar, do którego obrazy zostaną przeskalowane w celu uzyskania szybkich przebiegów treningowych. Podczas kursu będziemy sporo rozmawiać o tym parametrze. Zostaw na razie `224`."
      ]
    },
    {
      "metadata": {
        "id": "BG9qVA-rCzID",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "PATH = \"/content/data/old_polish_cars/old_polish_cars_two_classes_v2a-512-split/\"\n",
        "sz=224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlYRk9DrCzIF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ważne jest, aby mieć działający GPU NVidii. Zestaw bibliotek stosowany za kulisami do pracy z procesorami graficznymi NVidii nosi nazwę CUDA. Dlatego zanim przejdzisz dalej, upewnij się, że następująca linia zwraca wartość `True`. Jeśli masz z tym problemy, sprawdź FAQ i poproś o pomoc [na forum](http://forums.fast.ai)."
      ]
    },
    {
      "metadata": {
        "id": "8dz_nejWCzIG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Jor5wmQCzIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ponadto NVidia zapewnia specjalne przyspieszone funkcje do głębokiego uczenia w pakiecie o nazwie CuDNN. Chociaż nie jest to bezwzględnie konieczne, znacznie poprawi wydajność treningów i jest domyślnie uwzględnione we wszystkich obsługiwanych konfiguracjach fastai. Dlatego jeśli poniższe nie zwróci wartości `True`, warto sprawdzić, dlaczego."
      ]
    },
    {
      "metadata": {
        "id": "d-YAGIzICzIM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.enabled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgEwE9upCzIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Najpierw obejrzyj zdjęcia samochodów"
      ]
    },
    {
      "metadata": {
        "id": "1Mtl7fy_CzIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Biblioteka `fastai` zakłada, że posiadasz katalogi *train* i *valid*. Zakłada się także, że każdy katalog będzie zawierał podkatalogi dla każdej klasy, która ma zostać rozpaznana (w tym przypadku \"maluch\", \"polonez\" itp.)."
      ]
    },
    {
      "metadata": {
        "id": "Hao8v-boCzIU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tIQw1MgCzIW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir(f'{PATH}valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWZkE8OACzIZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files = os.listdir(f'{PATH}valid/maluch')[:5]\n",
        "files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3n1F1sn0CzIb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img = plt.imread(f'{PATH}valid/maluch/{files[2]}')\n",
        "plt.imshow(img);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KjBLgzY1CzId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Oto jak wyglądają dane surowe."
      ]
    },
    {
      "metadata": {
        "id": "nEyT4MFqCzId",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ok-ZFOzICzIf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img[:4,:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sAj1l5UTCzIh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Nasz pierwszy model: szybki start"
      ]
    },
    {
      "metadata": {
        "id": "DwiTJMKlCzIh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Użyjemy **wcześniej wytrenowanego** modelu, czyli modelu stworzonego przez kogoś innego dla rozwiązania innego problemu. Zamiast budować model od zera, aby rozwiązać podobny problem, jako punkt wyjścia wykorzystamy model wytrenowany na ImageNet (1,2 miliona obrazów i 1000 klas). Model ten to Convolutional Neural Network (CNN), rodzaj sieci neuronowej, którą używa się budując najnowocześniejsze modele rozpoznawania obrazów. Podczas tego kursu będziemy się uczyć wszystkiego o CNN.\n",
        "\n",
        "Będziemy używać model **resnet34**. resnet34 to wersja modelu, który wygrał konkurs ImageNet 2015. Tutaj jest więcej informacji na temat [modeli resnet] (https://github.com/KaimingHe/deep-residual-networks). Przyjrzymy się im dogłębnie później, ale na razie skupimy się na ich efektywnym wykorzystaniu.\n",
        "\n",
        "Oto jak wytrenować i zewaluować model *old polish cars* przy pomocy 3 linii kodu i w mniej niż 20 sekund:"
      ]
    },
    {
      "metadata": {
        "id": "kNO3nLkjCzIi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Odkomentuj poniższe informacje, jeśli chcesz zresetować swoje wstępne aktywacje\n",
        "# shutil.rmtree(f'{PATH}tmp', ignore_errors=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o5oyj7UCCzIj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "arch=resnet34\n",
        "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
        "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
        "learn.fit(0.01, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXJvEjkyCzIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Jak dobry jest ten model? Kilka lat temu, przy podobnym zadaniu, osiągano maksymalnie 80% dokładności. Ale konkurs rozpoznawania obrazów ogłoszony przez Kaggle, spowodował ogromny skok do 98,9% dokładności, a autor pewnej popularnej biblioteki deep learning zwyciężył w tym konkursie."
      ]
    },
    {
      "metadata": {
        "id": "KjLsgmvNCzIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analizowanie wyników: oglądanie zdjęć"
      ]
    },
    {
      "metadata": {
        "id": "hJKcExNOCzIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Oprócz ogólnego spojrzenia na wskaźniki warto przyjrzeć się poniższym przykładom:\n",
        "\n",
        "1. Kilka losowo wybranych poprawnych rozpoznań\n",
        "2. Kilka losowo wybranych nieprawidłowych rozpoznań\n",
        "3. Najbardziej poprawnie rozpoznania każdej klasy (tj. te z najwyższym prawdopodobieństwem z poprawnych)\n",
        "4. Najbardziej niepoprawne rozpoznania każdej klasy (tj. te z najwyższym prawdopodobieństwem z nieprawidłowych)\n",
        "5. Najbardziej niepewne rozpoznania (tj. te z prawdopodobieństwem najbliższym 0,5)."
      ]
    },
    {
      "metadata": {
        "id": "dO0rwfIeCzIn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# To jest etykieta dla danych walidacyjnych\n",
        "data.val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1gtI8n8CzIp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# stąd wiemy, że \"maluch\" to etykieta 0, a \"polonez\" to etykieta 1.\n",
        "data.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vg2yAqtCzIq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# daje to przewidywanie dla zestawu walidacyjnego. Prognozy są w skali logarytmicznej\n",
        "log_preds = learn.predict()\n",
        "log_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tb205BdICzIs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "log_preds[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhv6BInECzIt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "preds = np.argmax(log_preds, axis=1)  # od logarytmu prawdopodobieństwa do 0 lub 1\n",
        "probs = np.exp(log_preds[:,1])        # pr(polonez)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DV6NWhf-CzIu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
        "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rvxIeSYCzIv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plot_val_with_title(idxs, title):\n",
        "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
        "    title_probs = [probs[x] for x in idxs]\n",
        "    print(title)\n",
        "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KpQuoKVCzIw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0azZQfhCzIx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
        "\n",
        "def plot_val_with_title(idxs, title):\n",
        "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
        "    title_probs = [probs[x] for x in idxs]\n",
        "    print(title)\n",
        "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_GlGeykCzIx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 1. Kilka losowo wybranych poprawnych rozpoznań\n",
        "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fViFKoLQCzIz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 2. Kilka losowo wybranych nieprawidłowych rozpoznań\n",
        "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6n9FMkLCzI0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def most_by_mask(mask, mult):\n",
        "    idxs = np.where(mask)[0]\n",
        "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
        "\n",
        "def most_by_correct(y, is_correct): \n",
        "    mult = -1 if (y==1)==is_correct else 1\n",
        "    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvVnlwwYCzI1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(0, True), \"Most correct maluchs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJn-wGspCzI2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(1, True), \"Most correct polonezes\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VyKUcgXSCzI4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(0, False), \"Most incorrect maluchs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "onP7TissCzI5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(1, False), \"Most incorrect polonezes\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XfrTU7GSCzI6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
        "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tetIVNk7CzI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wybór tempa uczenia się"
      ]
    },
    {
      "metadata": {
        "id": "o8l-9-ylCzI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Tempo uczenia się* określa, jak szybko lub jak wolno chcesz aktualizować *wagi* (lub *parametry*). Tempo uczenia się jest jednym z najtrudniejszych parametrów do ustawienia, ponieważ ma znaczący wpływ na wydajność modelu.\n",
        "\n",
        "Metoda `learn.lr_find()` pomaga znaleźć optymalne tempo uczenia się. Wykorzystuje technikę opracowaną w 2015 roku, opisaną w publikacji [Cyclical Learning Rates for Training Neural Networks](http://arxiv.org/abs/1506.01186), gdzie po prostu ciągle zwiększamy tempo uczenia się, zaczynając od bardzo małej wartości, kończąc kiedy strata przestaje maleć. Możemy stworzyć wykres tempa uczenia się poprzez wszystkie porcje danych jednej epoki, aby zobaczyć, jak to wygląda.\n",
        "\n",
        "Najpierw tworzymy nowego ucznia `learn`, ponieważ chcemy wiedzieć, jak ustawić tempo uczenia się dla nowego (niewytrenowanego) modelu."
      ]
    },
    {
      "metadata": {
        "id": "t3YSHHhLCzI8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(arch, data, precompute=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJ_yLyUDCzI9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOGUwhufCzI-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nasz obiekt `learn` ma atrybut `sched`, który zawiera naszego 'planistę' szybkości uczenia się i ma kilka przydatnych wykresów, w tym:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E4Ywj0OACzI-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mpl.style.use('bmh')\n",
        "learn.sched.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kuCGacHKCzJA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that in the previous plot iteration is one iteration (or minibatch) of SGD. In one epoch there are (num_train_samples/num_iterations) of SGD.\n",
        "\n",
        "Zauważ, że na poprzednim wykresie jedna iteracja to iteracja (lub 'mini-batch' algorytmu SGD). Jedna epoka składa się z (num_train_samples/num_iterations) SGD.\n",
        "\n",
        "Widzimy wykres straty w stosunku do tempa uczenia się, aby zobaczyć, gdzie zmniejsza się nasza strata:"
      ]
    },
    {
      "metadata": {
        "id": "LDkWkg4SCzJA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JufM7FUHCzJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Strata wciąż wyraźnie maleje dla `lr=1e-2 (0.01)`, więc tego użyjemy. Zwróć uwagę, że optymalne tempo uczenia się może się zmieniać podczas treningu modelu, więc możesz chcieć ponownie uruchomić tę funkcję co jakiś czas."
      ]
    },
    {
      "metadata": {
        "id": "FxeI8XnNCzJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Polepszenie naszego modelu"
      ]
    },
    {
      "metadata": {
        "id": "RVI6rjNkCzJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Augmentacja danych"
      ]
    },
    {
      "metadata": {
        "id": "xtuzFyxJCzJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Jeśli spróbujesz trenować przez więcej epok, zauważysz, że zaczynamy *przetrenowywać*, co oznacza, że nasz model uczy się rozpoznawać konkretne obrazy w zbiorze treningowym, zamiast generalizować tak, że uzyskamy dobre wyniki również na zestawie walidacyjnym. Jednym ze sposobów rozwiązania tego problemu jest faktyczne stworzenie większej ilości danych, dzięki *augmentacji danych*. Chodzi o losową modyfikację obrazów w sposób, który nie powinien wpływać na ich interpretację, takich jak poziome odbijanie, powiększanie i obracanie.\n",
        "\n",
        "Możemy to zrobić, przekazując `aug_tfms` (*augmentation transforms*) do `tfms_from_model()`, z listą funkcji do zastosowania, które losowo zmieniają obraz, jak tylko chcemy. W przypadku zdjęć, które są w dużej mierze robione z boku (np. większość zdjęć samochodów, w przeciwieństwie do zdjęć zrobionych od góry, takich jak zdjęcia satelitarne), możemy użyć wstępnie zdefiniowanej listy funkcji `transforms_side_on`. Możemy również określić losowe powiększanie obrazów do określonej skali, dodając parametr `max_zoom`."
      ]
    },
    {
      "metadata": {
        "id": "wH31z6CXCzJC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpaEcsgdCzJC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_augs():\n",
        "    data = ImageClassifierData.from_paths(PATH, bs=2, tfms=tfms, num_workers=1)\n",
        "    x,_ = next(iter(data.aug_dl))\n",
        "    return data.trn_ds.denorm(x)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qdczm-uKCzJD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ims = np.stack([get_augs() for i in range(6)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfF5tf0BCzJE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plots(ims, rows=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5B42bhFwCzJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stwórzmy nowy obiekt `data`, który będzie mieć augmentacje w swoim zestawie transformacji."
      ]
    },
    {
      "metadata": {
        "id": "lbCoC7P7CzJF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = ImageClassifierData.from_paths(PATH, tfms=tfms)\n",
        "learn = ConvLearner.pretrained(arch, data, precompute=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naWchtjwCzJG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1e-2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0v5LSNUuCzJH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.precompute=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmYQnkIKCzJI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Domyślnie, gdy tworzymy ucznia (`learn`), ustawia on wszystkie oprócz ostatniej warstwy na *zamrożone*. Oznacza to, że kiedy wywołujemy `fit()`, uczeń aktualizuje wagi tylko w ostatniej warstwie."
      ]
    },
    {
      "metadata": {
        "id": "NjNc3w6xCzJI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1e-2, 3, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSwLzmf5CzJJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Co to jest parametr `cycle_len`? To, co tutaj robimy, to metoda *stochastycznego gradientu prostego z restartem (ang. stochastic gradient descent with restarts - SGDR)*, jest to wariant *wyżarzania szybkości uczenia (ang. learning rate annealing)*, która stopniowo zmniejsza tempo uczenia się w miarę postępu treningu. To pomaga, bo gdy zbliżamy się do optymalnych wag, chcemy podejść tam mniejszymi krokami.\n",
        "\n",
        "Jednakże możemy znaleźć się w części przestrzeni wagi, która nie jest bardzo odporna - to znaczy niewielkie zmiany wag mogą spowodować duże zmiany w stracie. Chcemy zachęcić nasz model do znalezienia części przestrzeni wag, które są zarówno dokładne, jak i stabilne. Dlatego od czasu do czasu zwiększamy szybkość uczenia się (jest to \"restart\" w \"SGDR\"), co zmusi model do przejścia do innej części przestrzeni wag, jeśli obecny obszar jest \"spiczasty\". Oto wykres tego, jak to może wyglądać, jeśli zresetujemy tempo uczenia się 3 razy (w tej publikacji nazywają to \"cyklicznym harmonogramem LR\", ang. 'cyclic LR schedule'):\n",
        "\n",
        "![SGDR](https://raw.githubusercontent.com/fastai/fastai/master/courses/dl1/images/sgdr.png)\n",
        "(Z publikacji [Snapshot Ensembles](https://arxiv.org/abs/1704.00109)).\n",
        "\n",
        "Liczba epok pomiędzy resetowaniem tempa uczenia się jest ustalana przez `cycle_len`, a liczba razy, kiedy to się dzieje, jest określana jako *liczba cykli*, i jest tym, co faktycznie przekazujemy jako drugi parametr do `fit()`. Oto jak wyglądało nasze rzeczywiste tempo uczenia się:"
      ]
    },
    {
      "metadata": {
        "id": "Hc6ICf5tCzJK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXRr9AxjCzJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nasza strata na zestawie walidacyjnym nie ulega znacznej poprawie, więc prawdopodobnie nie ma potrzeby dalszego trenowania samej ostatniej warstwy."
      ]
    },
    {
      "metadata": {
        "id": "MTsbJdjxCzJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ponieważ w tym momencie mamy już całkiem niezły model, możemy chcieć go zapisać, abyśmy mogli go załadować ponownie później bez trenowania od zera."
      ]
    },
    {
      "metadata": {
        "id": "euJMzX4LCzJL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.save('224_lastlayer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8SFQ5b1CzJL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.load('224_lastlayer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-DJv8BTCzJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tuning i 'różnicowe hartowanie kroku uczenia się'"
      ]
    },
    {
      "metadata": {
        "id": "Gsy0DSYNCzJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Teraz, gdy mamy już wytrenowaną dobrą warstwę końcową, możemy spróbować dopracować pozostałe warstwy. Aby powiedzieć uczniowi, że chcemy odblokować pozostałe warstwy, wystarczy użyć `unfreeze()`."
      ]
    },
    {
      "metadata": {
        "id": "QNnsEAmeCzJM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1hdzcS1CzJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Zauważ, że pozostałe warstwy zostały * już * wytrenowane do rozpoznawania zdjęć imagenetowych (podczas gdy nasze końcowe warstwy zostały losowo zainicjowane), więc chcemy uważać, aby nie zniszczyć dokładnie wyregulowanych wag, które już tam są.\n",
        "\n",
        "Ogólnie mówiąc, wcześniejsze warstwy (jak widzieliśmy) mają więcej funkcji ogólnego przeznaczenia. Dlatego oczekiwalibyśmy, że będą potrzebowali mniejszego dostrajania nowych zestawów danych. Z tego powodu użyjemy różnych poziomów nauki dla różnych warstw: pierwsze kilka warstw będzie na poziomie 1e-4, środkowe warstwy na 1e-3, a nasze warstwy FC opuścimy na 1e-2, tak jak poprzednio. Mówimy o tym jako o *zróżnicowanych tempach uczenia się*, chociaż nie ma standardowej nazwy dla tej technologii w literaturze, o której nam wiadomo."
      ]
    },
    {
      "metadata": {
        "id": "roSF0NsvCzJN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lr=np.array([1e-4,1e-3,1e-2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYjXZDYhCzJO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aP9jNdIXCzJP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Kolejną sztuczką, której tutaj użyliśmy jest dodanie parametru `cycle_mult`. \n",
        "\n",
        "Cykle są mierzone w epokach, więc cycle_len = 1 samo w sobie oznaczałoby ciągłe zmniejszanie szybkości uczenia się w trakcie jednej epoki, a następnie przeskakiwanie z powrotem do góry. Parametr cycle_mult mówi, aby pomnożyć długość cyklu przez coś (w tym przypadku 2), jak tylko ukończysz jeden cykl."
      ]
    },
    {
      "metadata": {
        "id": "148wKCKSCzJP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lu-AxNcDCzJR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Zauważ, że to, co przedstawiono powyżej, to tempo uczenia się *ostatnich warstw*. Współczynniki uczenia się wcześniejszych warstw są ustalane na tych samych wielokrotnościach ostatecznych poziomów warstw, zgodnie z pierwotnym żądaniem (tj. Pierwsze warstwy mają 100x mniejsze, a warstwy średnie 10x mniejsze szybkości uczenia się, ponieważ ustawiamy `lr=np.array([1e-4,1e-3,1e-2])`."
      ]
    },
    {
      "metadata": {
        "id": "PV0ATMczCzJR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.save('224_all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycnr_4XdCzJS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.load('224_all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NNJUKj4kCzJS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Jest jeszcze coś, co możemy zrobić z rozszerzeniem danych: użyj go w *czasie wnioskowania* (znanym również jako * czas testu*). Nic dziwnego, że jest to znane jako *augmentacia w czasie testu* lub po prostu *TTA*.\n",
        "\n",
        "TTA po prostu tworzy prognozy nie tylko na obrazach w twoim zbiorze sprawdzania poprawności, ale także tworzy prognozy dla pewnej liczby losowo rozszerzonych wersji ich (domyślnie używa oryginalnego obrazu wraz z 4 losowo rozszerzonymi wersjami). Następnie pobiera średnie prognozy z tych obrazów i wykorzystuje je. Aby użyć TTA w zestawie sprawdzania poprawności, możemy skorzystać z metody `TTA()` ucznia."
      ]
    },
    {
      "metadata": {
        "id": "JzDrRrw6CzJS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "log_preds,y = learn.TTA()\n",
        "probs = np.mean(np.exp(log_preds),0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXCwMYvMCzJU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy_np(probs, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xi1FJ3QxCzJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Zwykle widzę o 10-20% spadku błędu w tym zestawie danych podczas korzystania z TTA w tym momencie, co jest niesamowitym wynikiem dla tak szybkiej i prostej techniki!"
      ]
    },
    {
      "metadata": {
        "id": "9DSMHJV_CzJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analizowanie wyników"
      ]
    },
    {
      "metadata": {
        "id": "CRkpn44ZCzJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Macierz błędów (tablica pomyłek)"
      ]
    },
    {
      "metadata": {
        "id": "uYu6sycDCzJW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "preds = np.argmax(probs, axis=1)\n",
        "probs = probs[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sucz1bd7CzJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Popularnym sposobem analizy wyniku modelu klasyfikacyjnego jest użycie [macierzy błędów] (http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit Learn ma wygodną funkcję, którą możemy wykorzystać do tego celu:\n"
      ]
    },
    {
      "metadata": {
        "id": "waWb1krGCzJX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SL6EqSVnCzJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Możemy po prostu wydrukować macierz błędów lub możemy wyświetlić widok graficzny (który jest przydatny głównie dla osób z większą liczbą kategorii)."
      ]
    },
    {
      "metadata": {
        "id": "ViiNbHZQCzJX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mpl.style.use('default')\n",
        "mpl.style.use('seaborn-ticks')\n",
        "\n",
        "plot_confusion_matrix(cm, data.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OB7OQkBCzJZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ponowne spojrzenie na zdjęcia"
      ]
    },
    {
      "metadata": {
        "id": "HA4rSGKkCzJZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(0, False), \"Most incorrect maluchs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HG8AF3PeCzJa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_val_with_title(most_by_correct(1, False), \"Most incorrect polonezes\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K500_U6JCzJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Przegląd: proste kroki do wytrenowania światowej klasy klasyfikatora obrazu "
      ]
    },
    {
      "metadata": {
        "id": "_M2wjcbSCzJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Włącz augmentację danych oraz cache aktywacji (precompute=True)\n",
        "1. Użyj `lr_find()`, aby znaleźć najwyższe tempo uczenia się, przy którym strata (loss) jeszcze maleje\n",
        "1. Wytrenuj ostatnią warstwę z prekomputowanych aktywacji przez 1-2 epoki\n",
        "1. Wytrenuj ostatnią warstwę z augmentacją danych (tj. precompute = False) przez 2-3 epoki z cycle_len = 1\n",
        "1. Odblokuj wszystkie warstwy\n",
        "1. Ustaw dla wcześniejszych warstw 3x-10x mniejszy krok uczenia się niż dla kolejnych wyższych warstw\n",
        "1. Ponownie użyj `lr_find()`\n",
        "1. Trenuj całą sieć z cycle_mult = 2 aż do dopasowania"
      ]
    },
    {
      "metadata": {
        "id": "aZsIjZ8kCzJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Zrozumienie kodu naszego pierwszego modelu"
      ]
    },
    {
      "metadata": {
        "id": "S5BZUUUxCzJc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Spójrzmy na kod linia po linii.\n",
        "\n",
        "** tfms ** oznacza * transformacje *. `tfms_from_model` zajmuje się zmianą rozmiaru, kadrowaniem obrazu, początkową normalizacją (tworzenie danych za pomocą (średnia, odchylenie standardowe) (0,1)) i więcej."
      ]
    },
    {
      "metadata": {
        "id": "2EiMyRn4CzJc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(resnet34, sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkKeC-0vCzJc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Potrzebujemy <b> ścieżki </b> wskazującej na zbiór danych. W tej ścieżce będziemy również przechowywać tymczasowe dane i końcowe wyniki. `ImageClassifierData.from_paths` odczytuje dane z podanej ścieżki i tworzy gotowy zestaw danych do treningu."
      ]
    },
    {
      "metadata": {
        "id": "apPPuy5tCzJd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = ImageClassifierData.from_paths(PATH, tfms=tfms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yugLXdJOCzJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`ConvLearner.pretrained` buduje *ucznia* który zawiera wcześniej wytrenowany model. Ostatnia warstwa modelu musi zostać zastąpiona warstwą odpowiednich wymiarów. Ten model został wytrenowany dla 1000 klas, a ostateczna warstwa przewiduje wektor o prawdopodobieństwie 1000. Model dla starych polskich samochodów musi wyprowadzić wektor dwuwymiarowy. Poniższy schemat pokazuje w przykładzie, w jaki sposób zostało to zrobione w jednym z najwcześniej odnoszących sukces CNN. Warstwa \"FC8\" zostanie tutaj zastąpiona nową warstwą z 2 wyjściami.\n",
        "\n",
        "<img src=\"https://image.slidesharecdn.com/practicaldeeplearning-160329181459/95/practical-deep-learning-16-638.jpg\" width=\"500\">\n",
        "[original image](https://image.slidesharecdn.com/practicaldeeplearning-160329181459/95/practical-deep-learning-16-638.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "24oRP-_bCzJe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(resnet34, data, precompute=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yrmM053CzJe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Parametry* są wyuczane poprzez dopasowanie modelu do danych. * Hyparameters * to kolejny rodzaj parametru, którego nie można bezpośrednio nauczyć się ze zwykłego procesu treningowego. Parametry te wyrażają właściwości \"wyższego poziomu\" modelu, takie jak jego złożoność lub szybkość uczenia. Dwa przykłady hiperparametrów to *tempo uczenia się* i *liczba epok*.\n",
        "\n",
        "Podczas iteracyjnego trenowania sieci neuronowej, *wsad (batch)* lub *mini-wsad (mini-batch)* jest podzbiorem treningowych próbek używanych w jednej iteracji Stochastycznego Schodzenia Gradientowego (SGD). Epoka * * to pojedyncze przejście przez cały zestaw treningowy, który składa się z wielu iteracji SGD.\n",
        "\n",
        "Możemy teraz *dopasować (fit)* model; to znaczy, użyj *gradientowego spadku (gradient descent)*, aby znaleźć najlepsze parametry dla w pełni połączonej warstwy, którą dodaliśmy, która może oddzielać maluchowe obrazy od polonezowych obrazów. Musimy podać dwa hipertermery: *tempo uczenia się (learning rate)* (ogólnie 1e-2 lub 1e-3 jest dobrym punktem wyjścia, przyjrzymy się temu dalej) i *liczbie epok* (możesz podać wyższy poziom liczbę i po prostu przestań trenować, gdy zauważysz, że już się nie poprawia, a następnie uruchom ponownie z liczbą odnalezionych epok)."
      ]
    },
    {
      "metadata": {
        "id": "0lO6CCA3CzJe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1e-2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmkJAibYCzJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analiza wyników: strata i dokładność"
      ]
    },
    {
      "metadata": {
        "id": "g3ii-LsECzJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Kiedy uruchamiamy `learn.fit`, drukujemy 3 wartości wydajności (patrz wyżej.) Tutaj 0.03 jest wartością **straty** w zbiorze treningowym, 0.0226 jest wartością straty w zestawie walidacyjnym, a 0,9927 jest wartością dokładność weryfikacji. Jaka jest strata? Czym jest dokładność? Dlaczego nie pokazać dokładności?\n",
        "\n",
        "**Dokładność** to stosunek prawidłowej prognozy do całkowitej liczby prognoz.\n",
        "\n",
        "W uczeniu maszynowym funkcja **straty** lub koszt reprezentuje cenę zapłaconą za niedokładność prognoz.\n",
        "\n",
        "Stratę związaną z jednym przykładem w klasyfikacji binarnej daje:\n",
        " `-(y * log (p) + (1-y) * log(1-p))`\n",
        "gdzie `y` jest prawdziwą etykietą `x`, a `p` jest prawdopodobieństwem przewidzianym przez nasz model, że etykieta ma wartość 1."
      ]
    },
    {
      "metadata": {
        "id": "mNBdr4iWCzJg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def binary_loss(y, p):\n",
        "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYMvzI0iCzJh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "acts = np.array([1, 0, 0, 1])\n",
        "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
        "binary_loss(acts, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUqINnCjCzJi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Zauważ, że w naszym przykładzie zabawkowym powyżej nasza dokładność wynosi 100%, a nasza strata wynosi 0,16. Porównaj to ze stratą 0,03, którą otrzymujemy, podczas przewidywania maluchów i polonezów. \n",
        "\n",
        "Ćwiczenie: spróbuj zmodyfikować `preds` tak, aby uzyskać mniejszą stratę dla tego przykładu.\n",
        "\n",
        "**Przykład:** Oto przykład, jak obliczyć stratę dla jednego przykładu binarnego problemu klasyfikacji. Załóżmy dla obrazu x z etykietą 1, a model daje prognozę 0.9. W tym przypadku strata powinna być mała, ponieważ nasz model przewiduje etykietę $1$ z wysokim prawdopodobieństwem.\n",
        "\n",
        "`loss = -log (0.9) = 0.10`\n",
        "\n",
        "Załóżmy teraz, że x ma etykietę 0, ale nasz model przewiduje 0.9. W tym przypadku nasza strata powinna być znacznie większa.\n",
        "\n",
        "strata = -log (1-0,9) = 2,30\n",
        "\n",
        "\n",
        "- Ćwiczenie: spójrz na inne przypadki i przekonaj się, że to ma sens.\n",
        "- Ćwiczenie: w jaki sposób przepisałbyś `binary_loss` używając` if` zamiast `*` i `+`?\n",
        "\n",
        "Dlaczego po prostu nie zwiększyć dokładności? Strata klasyfikacji binarnej jest łatwiejszą funkcją do optymalizacji.\n"
      ]
    },
    {
      "metadata": {
        "id": "4tidoA78CzJi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}