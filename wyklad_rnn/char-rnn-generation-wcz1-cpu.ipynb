{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char-rnn-generation-wcz1-cpu.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1sv_cPvPEWEOrG9wS3fPjAOj-Wvs6kc0P",
          "timestamp": 1524467882593
        }
      ],
      "collapsed_sections": [
        "2fEFWi-FXM5p"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iVsYe7S5XM5G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/eBRPvWB.png)\n",
        "\n",
        "# Practical PyTorch: Generating Shakespeare with a Character-Level RNN\n",
        "\n",
        "[In the RNN classification tutorial](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) we used a RNN to classify text one character at a time. This time we'll generate text one character at a time.\n",
        "\n",
        "```\n",
        "> python generate.py -n 500\n",
        "\n",
        "PAOLTREDN:\n",
        "Let, yil exter shis owrach we so sain, fleas,\n",
        "Be wast the shall deas, puty sonse my sheete.\n",
        "\n",
        "BAUFIO:\n",
        "Sirh carrow out with the knonuot my comest sifard queences\n",
        "O all a man unterd.\n",
        "\n",
        "PROMENSJO:\n",
        "Ay, I to Heron, I sack, againous; bepear, Butch,\n",
        "An as shalp will of that seal think.\n",
        "\n",
        "NUKINUS:\n",
        "And house it to thee word off hee:\n",
        "And thou charrota the son hange of that shall denthand\n",
        "For the say hor you are of I folles muth me?\n",
        "```\n",
        "\n",
        "This one might make you question the series title &mdash; \"is that really practical?\" However, these sorts of generative models form the basis of machine translation, image captioning, question answering and more. See the [Sequence to Sequence Translation tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) for more on that topic."
      ]
    },
    {
      "metadata": {
        "id": "WamMk47AXM5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recommended Reading\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and understand Tensors:\n",
        "\n",
        "* http://pytorch.org/ For installation instructions\n",
        "* [Deep Learning with PyTorch: A 60-minute Blitz](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb) to get started with PyTorch in general\n",
        "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) for an in depth overview\n",
        "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) if you are former Lua Torch user\n",
        "\n",
        "It would also be useful to know about RNNs and how they work:\n",
        "\n",
        "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) shows a bunch of real life examples\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is about LSTMs specifically but also informative about RNNs in general\n",
        "\n",
        "Also see these related tutorials from the series:\n",
        "\n",
        "* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) uses an RNN for classification\n",
        "* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb) builds on this model to add a category as input"
      ]
    },
    {
      "metadata": {
        "id": "lGN3xU17XpWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# setup"
      ]
    },
    {
      "metadata": {
        "id": "kkkCqSEBXsYh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3aeeafa1-f5b4-4dd6-fa2c-1a8a187d39fb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524482096322,
          "user_tz": -120,
          "elapsed": 5450,
          "user": {
            "displayName": "Kamsiulek Malutki",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118138569128465864586"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kAJoAgQTJyM_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "dataset_path = Path.home() / 'data/rnn_generator'; dataset_path\n",
        "tmp_path = dataset_path / 'tmp/'\n",
        "!mkdir -p $tmp_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4wAU8Y6XsSl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d31feaed-6d63-49cc-8c85-0523508d7d05",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524573591995,
          "user_tz": -120,
          "elapsed": 1732,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lah /content/data/rnn_generator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.1M\r\n",
            "drwxr-xr-x 3 root root 4.0K Apr 24 12:39 .\r\n",
            "drwxr-xr-x 3 root root 4.0K Apr 24 09:58 ..\r\n",
            "-rw-r--r-- 1 root root 709K Apr 24 10:14 mickiewicz.txt\r\n",
            "-rw-r--r-- 1 root root 219K Apr 23 17:58 pan_tadeusz.txt\r\n",
            "drwxr-xr-x 3 root root 4.0K Apr 24 12:35 tmp\r\n",
            "-rw-r--r-- 1 root root 142K Apr 24 10:05 witkacy_szewcy.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2tJDT2lCceZL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# vm monitoring"
      ]
    },
    {
      "metadata": {
        "id": "bKdCiolHcg4e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "\n",
        "def print_memsize():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(f'{process.memory_info().rss / 1024**3:.5} GB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "diBUUyOociRy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc7d6fcb-4121-46b3-abe6-1318276f21a8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524504229297,
          "user_tz": -120,
          "elapsed": 560,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print_memsize()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12249 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2hTjsshick9K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8KbaMvrXM5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data\n",
        "\n",
        "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
      ]
    },
    {
      "metadata": {
        "id": "YLH7c2gwoLlP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# fn = 'data/tiny-shakespeare.txt'\n",
        "# fn = dataset_path / 'mickiewicz.txt'\n",
        "# fn = dataset_path / 'witkacy_szewcy.txt'\n",
        "fn = dataset_path / 'pan_tadeusz.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9H83p3sXM5L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7074a079-4647-42f8-88b6-c24f23ed1f89",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524575226450,
          "user_tz": -120,
          "elapsed": 1457,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "# file = unidecode.unidecode(open(fn).read())\n",
        "file = open(fn).read()\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "# ascii only\n",
        "# all_characters = string.printable\n",
        "# n_characters = len(all_characters)\n",
        "\n",
        "\n",
        "# all chars found in file\n",
        "all_characters = sorted(list(set(file))); print(all_characters[:10])\n",
        "n_characters = len(all_characters); print(n_characters)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 203037\n",
            "['\\n', ' ', '!', '\"', '%', \"'\", '(', ')', ',', '-']\n",
            "89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lL_XOG-fXM5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make inputs out of this big string of data, we will be splitting it into chunks."
      ]
    },
    {
      "metadata": {
        "id": "_zwmRSAHXM5T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e177e6f7-2a56-4081-cb4d-782031acb00d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524575236233,
          "user_tz": -120,
          "elapsed": 581,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "chunk_len = 400\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "się wparło,\n",
            "Ale za każdym razem trzech nogi zadarło,\n",
            "Wiec uciekli pod lamus; a już był poranek.\n",
            "Pan Stolnik wesoł wyszedł ze strzelbą na ganek,\n",
            "I skoro s pod lamusa moskal łeb wychylił,\n",
            "On dawał zaraz ognia a nigdy nie mylił,\n",
            "Za każdym razem czarny kaszkiet w trawę padał,\n",
            "I już się rzadko który z za ściany wykradał.\n",
            "Stolnik widząc strwożone swe nieprzyjaciele,\n",
            "Myślił zrobić wycieczkę, porwał karabe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X5cFLx6WXM5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the Model\n",
        "\n",
        "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
      ]
    },
    {
      "metadata": {
        "id": "tZ8chQcVXM5X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62XSRFgkXM5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inputs and Targets"
      ]
    },
    {
      "metadata": {
        "id": "UaOPvn0rXM5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
      ]
    },
    {
      "metadata": {
        "id": "q0H2nwMMXM5a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "3800d1e0-73cc-4a92-f7f5-9faaafbe9d00",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524575242750,
          "user_tz": -120,
          "elapsed": 1732,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('ala ma kota'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable containing:\n",
            " 41\n",
            " 52\n",
            " 41\n",
            "  1\n",
            " 53\n",
            " 41\n",
            "  1\n",
            " 51\n",
            " 55\n",
            " 59\n",
            " 41\n",
            "[torch.LongTensor of size 11]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Su49JvFXM5d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "metadata": {
        "id": "mLzzsbTRXM5d",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSJ_szQTXM5f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating\n",
        "\n",
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
      ]
    },
    {
      "metadata": {
        "id": "2ecqC4rWXM5f",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZY0fPgEXM5h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "-pM5T97tXM5h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A helper to print the amount of time passed:"
      ]
    },
    {
      "metadata": {
        "id": "hQnLeX-TXM5h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0pntPTWEXM5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main training function"
      ]
    },
    {
      "metadata": {
        "id": "QKb7-MeXXM5j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[c], hidden)\n",
        "        loss += criterion(output, target[c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data[0] / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tyo69fakXM5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we define the training parameters, instantiate the model, and start training:"
      ]
    },
    {
      "metadata": {
        "id": "ILThkaRPXM5k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3001
        },
        "outputId": "87a87edc-b107-4ecc-c1b0-d6d0650121ad",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524576160191,
          "user_tz": -120,
          "elapsed": 905125,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 2000 # 3000\n",
        "print_every = 100\n",
        "plot_every = 1\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "print(decoder, flush=True)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, n_epochs + 1)):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        e = evaluate('Wh', 200)\n",
        "        print('\\n[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(e, '\\n', flush=True)\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (encoder): Embedding(89, 100)\n",
            "  (gru): GRU(100, 100)\n",
            "  (decoder): Linear(in_features=100, out_features=89)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▍         | 99/2000 [00:44<14:08,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[0m 44s (100 5%) 2.3588]\n",
            "Whąc pole go_ie wiszarzy ieśonie, Panie zasię,\n",
            "Bowie takowinu towojyci kurzekniwa koć przesty,\n",
            "Zsię wrzysta tenta mierząci się polęczyi piłero złorzłowyści wkiera zakrzyj,\n",
            "Kicu nassię szywa pikrzył sczn \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|▉         | 199/2000 [01:28<13:22,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[1m 29s (200 10%) 2.2161]\n",
            "Whać  lak kraz wyskowanąd że starach i wiak sto sialicy grzaka -- niewty i śłodził ko posię przyna mnierzy na zierszem stawieć prokaci,\n",
            "Zale to do jakę głozczecz\n",
            "-- Wizredzi i w mieli prystały, padówrac \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 299/2000 [02:13<12:37,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[2m 13s (300 15%) 2.3984]\n",
            "Whużem\n",
            "Natrzycy przydowońchmo stać s kim zamieniej dokon pięko obo kierobie,\n",
            "W pradrzy strzykła dłożyniecy kowa stał spubiały,\n",
            "Na krzych obryłoniemiem, krzykły storce do stranie,\n",
            "Jako krzychwą strzy dła \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 399/2000 [02:58<11:54,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[2m 58s (400 20%) 2.0652]\n",
            "Whęcie młyści w niesktów Horwany barkalnem lapiewiem romienia,\n",
            "Prywa stem o głąkł dojania do w rzena wilieka czan płował do okrywaział zdo dona odziesta pociego Pam ręko Dzukał, po ramiem mnie do podeus \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 499/2000 [03:42<11:10,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[3m 43s (500 25%) 2.1573]\n",
            "Whuch bogła;\n",
            "W buczniem poszech séj z gdy prziebia,\n",
            "Mowiem, z czykome.\n",
            "\n",
            "    Tążał siądzieje, asz nim odkoście głowa mimnie głojego jak dom sądzich nam goła, powalków,\n",
            "Zwosta zawiedzie dzieru Teludnie w  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 599/2000 [04:27<10:25,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[4m 27s (600 30%) 2.0797]\n",
            "Whał szele, wojskomerzem.\n",
            "Niecz praskał i wrócił,\n",
            "I podział szeredzi nim czaszem oczuchany,\n",
            "Moczy ku więdzonu po prawnie\n",
            "-- Do jenach, w towanici,\n",
            "Ale charz zawiedy obie zwiele się kiesta! czył w luczyl \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 699/2000 [05:12<09:40,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[5m 12s (700 35%) 2.1647]\n",
            "Whusze o obrodzić szęściu, śćmię waczelu stołał choć ręko i odni a prawnie i bławał\n",
            "Powszaski Hradził, bięła i pielski kolić.\n",
            "Telucharnie murecz po grubie.\n",
            "\n",
            "\n",
            "\n",
            "Hrabiał; na wiemy star oka chwili pożewało  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 799/2000 [05:57<08:56,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[5m 57s (800 40%) 2.0398]\n",
            "Whałt domosłem nięc zastem się więc, wykrznał;\n",
            "Od skrzecz na zawznie zelu, szczed poteli w do między dary,\n",
            "Śliwił szkałtą, znala Pan okora:\n",
            "Czerwszy dobarzczy.\n",
            "O tak s cepras grałki,\n",
            "I do myśnie, z zeru \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 899/2000 [06:41<08:12,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[6m 42s (900 45%) 2.3444]\n",
            "Whyją w prawéj usie bardzo podźwieli wich, obaci,\n",
            "I w laszczany.\n",
            "\n",
            "«Graszem przezwi szlach odartował; boże Hrabia s przyprzy na młodzie;\n",
            "Na na pobał, rozbNował paniozelyów,\n",
            "W w ramiają grzechynieru;\n",
            "Brzy \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 999/2000 [07:26<07:27,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[7m 27s (1000 50%) 1.8919]\n",
            "Whijolach się darjał i uczko do trawnie,\n",
            "Ob w wiałem zabita\n",
            "Niebuplkość, o postaniał,\n",
            "Przebia stołą jadatniej kamek werzysteli, obrzachała na niebucionéj siebia przytali odwierz mi strzeli znadając, jes \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 1099/2000 [08:11<06:43,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[8m 12s (1100 55%) 2.0479]\n",
            "Whydziu  glik, Ceserze!\n",
            "Widać to krenienie, stronie siał pan kolił po podsieżne to in w nie wrócca w ostawana wiedzie? że żylą,\n",
            "Krzywa przy popanie niewszystwej wilcze wyprosory Pan mienie sychodzi rozo \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 1199/2000 [08:56<05:58,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[8m 56s (1200 60%) 2.0531]\n",
            "Whéj na potakł;\n",
            "Rowie je z pięczystać s który i piedos miał ssobać zwierz mówne i od przestój cały\n",
            "Tak za jedŻe od ostaczeń nie wychcie zmienie;\n",
            "Rzekty mój mu za polał\n",
            "Wodat młodzie Berajęłem,\n",
            "A trzeczt \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 1299/2000 [09:40<05:13,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[9m 41s (1300 65%) 2.0607]\n",
            "Whiępsów,\n",
            "Z napernie, szczena i konajdzie do lotystwo, wypata,\n",
            "Chwodna lewa dwierze niém okował do choć kłótków, strzaskośnia, nie lisami wielkie.\n",
            "Podkomy mając się fanownka,\n",
            "Ili w lasias zawsze i dworz \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 1399/2000 [10:25<04:28,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[10m 25s (1400 70%) 1.9414]\n",
            "Whąstów kota;\n",
            "Tenę widoczę\n",
            "Zwierzegów się, też Hraba się się naledziem strzeli róstwy zioda.\n",
            "\n",
            "Wzrosta się się paniało ciestrzu Sanono siwy\n",
            "Światę się swoła; się wiógów też w przedewł, strasła.\n",
            "\n",
            "Niemim R \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 1499/2000 [11:09<03:43,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[11m 10s (1500 75%) 1.9627]\n",
            "Whistęcie bielki grzyknął;\n",
            "Pakował Pan się jak posta?\n",
            "W nie końce i klewał były,\n",
            "Stolczyny od w wiém wszyska pladzilnym\n",
            "Na do jéj były sam patrzego siędze,\n",
            "Wypisie zadrzegle mówi w pomnie nagdyle że mu  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 1599/2000 [11:54<02:59,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[11m 55s (1600 80%) 1.9424]\n",
            "Whcie! stoły był w cełos zwiacie ustary obora,\n",
            "W u na był wrażo strwaszaję.\n",
            "Już maję o cilkowąc się zarwora,\n",
            "I szarcym się ukraztwie gorzetewga grania Robak zebyło zachać jak zamku był był która skili,\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 1699/2000 [12:39<02:14,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[12m 39s (1700 85%) 2.1208]\n",
            "Whzieczył podanie\n",
            "Po wierz Tadeusz i sercia daléj piewszy niemych,\n",
            "Niemowny szeroka, palejemi uczął, wzerwie i tylko,\n",
            "Co się w szeracy się więcz i pawciu niechowią,\n",
            "Między padku poiedź sobie,\n",
            "Ją radnie  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 1799/2000 [13:24<01:29,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[13m 24s (1800 90%) 1.8191]\n",
            "Whojdzie,\n",
            "Chciała cuta dworzy podnosuje mi kontość przedziewie, przecie: dworzy.\n",
            "\n",
            "Ale dzie. Jaga polero zamkoma wyrote,\n",
            "Co goście i głową oczy,\n",
            "Zszym potém który, rodzami pojętwa,\n",
            "Zaszyst do doboła w gr \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 1899/2000 [14:09<00:45,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[14m 9s (1900 95%) 1.9731]\n",
            "Whojen; i wystrzelby odzawek\n",
            "Go którą roskusząc w Litwiony, jedne dumania,\n",
            "Kudził posta w ku lubi drzewa;\n",
            "Tyła parodziła do zab i już sporemu\n",
            "Cię rzekł dało biętał\n",
            "A sątwe jako kikto wyglądza, s była si \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1999/2000 [14:53<00:00,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[14m 54s (2000 100%) 1.9794]\n",
            "Whętką zdanie.\n",
            "Polno wielby sposoby sam jedne brzecie westajszy.\n",
            "Powieli strzelcy w pole jak Leciek to czasku mieszkanie co szycy do się Sprzód trz obek się obremarz Pan Stałta srewnąt psercić doblowéj  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 2000/2000 [14:54<00:00,  2.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dXrPD94SXM5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting the Training Losses\n",
        "\n",
        "Plotting the historical loss from all_losses shows the network learning:"
      ]
    },
    {
      "metadata": {
        "id": "meKCxPo3XM5n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4f1a6479-59dd-4bf0-90d4-c66f6e0736ca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524576161079,
          "user_tz": -120,
          "elapsed": 841,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6298668048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4XCSyIUQwuEkkQshhMP9P5zXdtceCzaYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f62d5d22550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2fEFWi-FXM5p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating at different \"temperatures\"\n",
        "\n",
        "In the `evaluate` function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n",
        "\n",
        "We can see the effects of this by adjusting the `temperature` argument."
      ]
    },
    {
      "metadata": {
        "id": "gBm5ibSnXM5p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "204d2eb8-1dca-49ea-e2bf-dc80d0aad2ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524507399127,
          "user_tz": -120,
          "elapsed": 556,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate('Th', 200, temperature=0.8))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thał, a połuszki?\n",
            "Mały jej w drożąga z nalik z kończył popieczny okryż brapa,\n",
            "Był się w naszej się się strugi się bietczę--\n",
            "       je z moje wiecze pomory,\n",
            "Oszajego kramiele bo widzieraz wpada mobieje s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DnStt-FzXM5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lower temperatures are less varied, choosing only the more probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "D3mkq_sCXM5r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f84fdb17-bfb7-4b1f-c291-c02e73666dea",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524507409942,
          "user_tz": -120,
          "elapsed": 630,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate('Th', 200, temperature=0.2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tho mieszczył się podrował się się się się się wielki się nieszara,\n",
            "Wierze się się pod przyjacień się wierczy,\n",
            "A wiecznie się podrował, \n",
            "Wiedził się zapał się się się wierzy podrował,\n",
            "Zabaczył się do do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l508QP1LXM5t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Higher temperatures more varied, choosing less probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "SxhfgI-PXM5u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2e28cdd0-2ed5-4cbd-f56d-05b558aff212",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524507406845,
          "user_tz": -120,
          "elapsed": 530,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate('Th', 200, temperature=1.4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ThÓ)\n",
            "\n",
            "tańserych waląscie! Has romu leży.\n",
            "Wojrźna? Lźitaty\n",
            "szłysenne, kryjy rutu,\n",
            "Od rycionabyfrapy; - posru;\n",
            "Ni mrzewli, szmurek rzuży:\n",
            "\"Szrozabamiąli: WIFTą. SŁEMIÓN PISTNOść jakiasry, rąm3-słyśny, \n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-UQoZYk2XM5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "* Train with your own dataset, e.g.\n",
        "    * Text from another author\n",
        "    * Blog posts\n",
        "    * Code\n",
        "* Increase number of layers and network size to get better results"
      ]
    },
    {
      "metadata": {
        "id": "pFHHvkI6XM5w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next**: [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Uz_M0SPnEAoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ]
    },
    {
      "metadata": {
        "id": "DHG0vz1T3S02",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ALLCHARS, MODEL = ['all_characters', 'model']\n",
        "\n",
        "fn_pan_tadeusz = {ALLCHARS: 'all_characters.pan_tadeusz.p', MODEL: 'pan_tadeusz.h100.l1.e2000.cpu.torch'}\n",
        "\n",
        "fn_dict = fn_pan_tadeusz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ggvwFPKz3PuX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save all_characters\n",
        "import pickle\n",
        "\n",
        "pickle.dump(all_characters, open(tmp_path / fn_dict[ALLCHARS], 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtIz5fic3tYr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# all_characters = pickle.load( open( tmp_path / fn_dict[ALLCHARS], 'rb' ) )\n",
        "# n_characters = len(all_characters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6vMkPRyEFFv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "5dcea229-9277-4dcb-b050-e221de48aa5e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524576946700,
          "user_tz": -120,
          "elapsed": 744,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "decoder.state_dict"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of RNN(\n",
              "  (encoder): Embedding(89, 100)\n",
              "  (gru): GRU(100, 100)\n",
              "  (decoder): Linear(in_features=100, out_features=89)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "SNjVNuV7GKxC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "727c37fb-f08b-43f0-ecaf-047ab52833fb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524576951519,
          "user_tz": -120,
          "elapsed": 948,
          "user": {
            "displayName": "Wojtek Czarnowski",
            "photoUrl": "//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg",
            "userId": "115130698336476923651"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model_path = tmp_path / fn_dict[MODEL]\n",
        "torch.save(decoder, model_path)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fxJmcpSVElhc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# decoder = torch.load(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}