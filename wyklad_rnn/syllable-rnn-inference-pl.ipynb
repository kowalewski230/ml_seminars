{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5y5zxU-tMBqb"
   },
   "source": [
    "# Generacja za pomocą RNN przy użyciu GPU lub CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iQFiQEg2M7_L"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataset_path = Path('data/rnn_generator'); print(dataset_path)\n",
    "tmp_path = dataset_path / 'tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1525795834067,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "M7tZoCQ87701",
    "outputId": "8851ef5d-59e4-4906-baef-dcf899e3446b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "USE_GPU = torch.cuda.is_available(); \n",
    "# USE_GPU = False; \n",
    "\n",
    "print(f'USE_GPU={USE_GPU}')\n",
    "\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gsxhdCiH1GH8"
   },
   "outputs": [],
   "source": [
    "ALLTOKS, MODEL = ['all_tokens', 'model']\n",
    "\n",
    "fn_pan_tadeusz = {ALLTOKS: 'all_tokens.pan_tadeusz.p', MODEL: 'pan_tadeusz.h300.l2.e3000.gpu.torch'}\n",
    "\n",
    "fn_dict = fn_pan_tadeusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1525795835698,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "fqi3uGN3XJR3",
    "outputId": "75125330-75ea-4b92-f90f-d75fea79c6a5"
   },
   "outputs": [],
   "source": [
    "tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1724,
     "status": "ok",
     "timestamp": 1525795837458,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "5O7rXy8lXM1l",
    "outputId": "577b06f5-8d45-41c5-9f33-eb9c778c9090"
   },
   "outputs": [],
   "source": [
    "ls -lah $tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abA8YbvTM9P7"
   },
   "source": [
    "## Ładowanie listy all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1525795838174,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "-g3yLkRlM8Ci",
    "outputId": "0a0e581d-3f0d-4dcf-e021-be1ba0b8c07c"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "all_tokens = pickle.load( open( tmp_path / fn_dict[ALLTOKS], 'rb' ) ); print(all_tokens[:10])\n",
    "n_tokens = len(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klVO2LLbMxHh"
   },
   "source": [
    "## Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q3kvxKIPMzyC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(to_gpu(torch.zeros(self.n_layers, 1, self.hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3203,
     "status": "ok",
     "timestamp": 1525795842227,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "M2wurTvHMUsq",
    "outputId": "d4f255ed-5344-4d9f-cf10-bbe3922324f1"
   },
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def tok_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_tokens.index(string[c])\n",
    "    return Variable(to_gpu(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_corpus_syl = dataset_path/'pan_tadeusz.syl1.txt'\n",
    "\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "file = open(fn_corpus_syl).read()\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n",
    "\n",
    "# taken from fastai/text.py\n",
    "import re, string\n",
    "# remove +,- chars from punctuation set to keep sylables e.g.'--PO++' intact\n",
    "punctuation=re.sub('[\\+-]', '', string.punctuation)\n",
    "re_tok = re.compile(f'([{punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "file_tok = tokenize(file); len(file_tok), file_tok[:8]\n",
    "file_tok_len = len(file_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_token_list = file_tok[20:30]; print(a_token_list)\n",
    "print(tok_tensor(a_token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 400\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_tok_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file_tok[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syl2str(a_list, delim='/'): return ' '.join(a_list).replace('++ --', delim)\n",
    "print(syl2str(random_chunk()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tWUvpDlFMUvZ"
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str=[all_tokens[1]], predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = tok_tensor(prime_str)\n",
    "    predicted = list(prime_str)  # need a copy of the list\n",
    "\n",
    "    # Use priming token list to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0].item()\n",
    "        \n",
    "        # Add predicted token to the list and use as next input\n",
    "        predicted_token = all_tokens[top_i]\n",
    "        predicted.append(predicted_token)\n",
    "        inp = tok_tensor([predicted_token])\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1525795845340,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "nW605sPbPDtf",
    "outputId": "7fd8ac23-ec21-4b7e-85be-41ad085671b5"
   },
   "outputs": [],
   "source": [
    "n_epochs = 300 # 3000\n",
    "print_every = 100\n",
    "plot_every = 1\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_tokens, hidden_size, n_tokens, n_layers)\n",
    "print(decoder, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "448Y72-nQBtp"
   },
   "source": [
    "## Wczytywanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1525795846408,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "XLY4aFklQAqt",
    "outputId": "d9595319-de20-4659-a315-a70239e301c7"
   },
   "outputs": [],
   "source": [
    "model_path_cpu = tmp_path / fn_dict[MODEL]\n",
    "decoder = torch.load(model_path_cpu)\n",
    "print(decoder, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Fmg9fOb2oggW"
   },
   "outputs": [],
   "source": [
    "decoder.gru.flatten_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFGkMgTMO9g8"
   },
   "source": [
    "## Generowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eDlhLm5M34yQ"
   },
   "outputs": [],
   "source": [
    "# priming strings\n",
    "# pan_tadeusz: kon, bę, Tad, Tadeusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3911,
     "status": "ok",
     "timestamp": 1525795853115,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "oIM7xrfOMU0S",
    "outputId": "06747b23-8bb5-43a8-ac3b-22bb576a91ff"
   },
   "outputs": [],
   "source": [
    "prime_tokl = file_tok[13:18]\n",
    "print(syl2str(evaluate(prime_tokl, 200, temperature=0.8), delim='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3126,
     "status": "ok",
     "timestamp": 1525795856254,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "mIU6dyzRMU25",
    "outputId": "8c7ab88d-b65b-4f73-e1f6-30fde326e1c0"
   },
   "outputs": [],
   "source": [
    "print(syl2str(evaluate(prime_tokl, 200, temperature=0.2), delim='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1839,
     "status": "ok",
     "timestamp": 1525795858105,
     "user": {
      "displayName": "Kamsiulek Malutki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "118138569128465864586"
     },
     "user_tz": -120
    },
    "id": "OPYzLn5jMU5x",
    "outputId": "bd07af1f-cfc6-4d1b-9148-11076f0ff506"
   },
   "outputs": [],
   "source": [
    "print(syl2str(evaluate(prime_tokl, 200, temperature=1.4), delim='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FIsFkxsFMVBS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn-generator-inference-wcz2-gpu.ipynb",
   "provenance": [
    {
     "file_id": "1PMTT-NUS-yBYHz9iXOlYMYt-jTKgrwXF",
     "timestamp": 1524578004978
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
