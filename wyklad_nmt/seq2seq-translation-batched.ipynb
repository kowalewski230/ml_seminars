{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq-translation-batched-pl-wcz1.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1LdwpSTwV_jrnw7vx0ponFH2q2vq2Nsug","timestamp":1524856859127}],"collapsed_sections":["yHtNHu50jM_O"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0pi0-vQzjM-a","colab_type":"text"},"cell_type":"markdown","source":["![](https://i.imgur.com/eBRPvWB.png)\n","\n","# Tłumaczenie z użyciem sieci Sequence to Sequence z koncentracją\n","\n","\n","W tym projekcie nauczymy sieć neuronową, jak tłumaczyć z angielskiego na polski.\n","\n","```\n","[KEY: > input, = target, < output]\n","\n","> there are pretty flowers in the garden .\n","= w ogrodzie są piękne kwiaty .\n","< w ogrodzie są piękne kwiaty .\n","\n","> i can't translate this sentence .\n","= nie potrafię przetłumaczyć tego zdania .\n","< nie potrafię przetłumaczyć tego zdania .\n","\n","> how come you know english so well ?\n","= jak to się stało , że tak dobrze znasz angielski ?\n","< skąd znasz angielskiego tak dobrze ? \n","\n","> things have gotten better now .\n","= sytuacja się poprawiła .\n","< to się jeszcze jeszcze teraz lepiej .\n","```\n","\n","\n","... z różnym powodzeniem.\n","\n","Jest to możliwe dzięki prostej, ale potężnej idei sieci [sequence to sequence](http://arxiv.org/abs/1409.3215), w której dwie rekurencyjne sieci neuronowe współpracują ze sobą, aby przekształcić jedną sekwencję w drugą. Sieć kodera kondensuje sekwencję wejściową do pojedynczego wektora, a sieć dekodera rozwija ten wektor w nową sekwencję.\n","\n","Aby ulepszyć ten model, użyjemy [mechanizmu koncentracji](https://arxiv.org/abs/1409.0473), który pozwoli dekoderowi nauczyć się skupiać na pewnej części sekwencji wejściowej."]},{"metadata":{"id":"bO8jBTPCjM-b","colab_type":"text"},"cell_type":"markdown","source":["# Model Sequence to Sequence\n","\n","\n","Sieć [Sequence to Sequence](http://arxiv.org/abs/1409.3215) lub sieć seq2seq, lub sieć [Encoder Decoder](https://arxiv.org/pdf/1406.1078v3.pdf), jest to model składający się z dwóch oddzielnych RNN'ów zwanych **koderem** i **dekoderem**. W każdym kroku koder odczytuje sekwencję wejściową po jednym elemencie a oddaje wektor. Końcowy wynik kodera jest utrzymywany jako wektor **kontekstu**. Dekoder wykorzystuje ten wektor kontekstu, aby wytworzyć sekwencję wyjść krok po kroku.\n","\n","![](https://github.com/wojtekcz/ml_seminars/blob/master/wyklad_nmt/images2/encoder-decoder.png?raw=true)\n","\n","Podczas korzystania z pojedynczego RNN istnieje relacja jeden do jednego pomiędzy wejściami i wyjściami. Szybko napotkalibyśmy problemy z różnymi kolejnościami sekwencji i długościami, które są częste podczas tłumaczenia. Rozważ proste zdanie \"Je ne suis pas le chat noir\" & rarr; \"I am not the black cat\" (\"Nie jestem czarnym kotem\"). Wiele słów ma całkiem jednoznaczne tłumaczenie, na przykład \"cat\" &rarr; \"kot\". Jednak różne gramatyki powodują, że słowa występują w różnych kolejnościach, np. \"black cat\" &rarr; \"kot czarny\". Istnieją również konstrukcje \"... have gotten better\" &rarr; \"... się poprawiła\", które sprawiają, że dwa zdania mają różne długości.\n","\n","Model seq2seq, kodując wiele wejść do jednego wektora i dekodując z jednego wektora na wiele wyjść,  uwalnia nas od ograniczeń kolejności i długości sekwencji. Zakodowana sekwencja jest reprezentowana przez pojedynczy wektor, pojedynczy punkt w N-wymiarowej przestrzeni sekwencji. W idealnym przypadku punkt ten można uznać za \"znaczenie\" sekwencji.\n","\n","Ten pomysł może zostać przedłużony poza sekwencje. Zadania opisywania obrazów pobierają [obraz jako dane wejściowe i produkują opis](https://arxiv.org/abs/1411.4555) obrazu (img2seq). Niektóre zadania generowania obrazów pobierają [opis jako dane wyjściowe i generują obraz](https://arxiv.org/abs/1511.02793) (seq2img). Takie modele można ogólnie nazwać sieciami \"koder dekoder\"."]},{"metadata":{"id":"FgcvjusvjM-c","colab_type":"text"},"cell_type":"markdown","source":["## Mechanizm koncentracji (Attention)\n","\n","Wektor o stałej długości jest odpowiedzialny za zakodowanie całego \"znaczenia\" sekwencji wejściowej, bez względu na jej długość. Z powodu rożnorodności językowej jest to bardzo trudny problem. Wyobraź sobie dwa prawie identyczne zdania, dwadzieścia słów, różniące się jednym tylko słowem. Zarówno kodery, jak i dekodery muszą być wystarczająco zniuansowane, aby reprezentować tę zmianę jako nieznacznie inny punkt w przestrzeni.\n","\n","**Mechanizm koncentracji** [wprowadzony przez Bahdanau i innych](https://arxiv.org/abs/1409.0473) rozwiązuje ten problem, dając dekoderowi możliwość \"koncentrowania się\" na fragmentach danych wejściowych, zamiast polegania na na pojedynczym wektorze. W każdym kroku dekoder może wybrać inny fragment sekwencji wejściowej do rozważenia.\n","\n","![](https://github.com/wojtekcz/ml_seminars/blob/master/wyklad_nmt/images2/encoder-inputs-decoder-outputs.png?raw=true)\n","\n","Koncentracja jest obliczana przy użyciu bieżącego stanu ukrytego i każdego wyjścia kodera, aby utworzyć nowy wektor, który ma taki sam rozmiar jak sekwencja wejściowa nazwany *wagami koncentracji*. Te wagi są mnożone przez wyjścia koderów w celu utworzenia nowego wektora *kontekstu*. Wektor kontekstu i stan ukryty jest następnie wykorzystywany do predykcji kolejnego elementu wyjścia.\n","\n","![](https://github.com/wojtekcz/ml_seminars/blob/master/wyklad_nmt/images2/attention-module-input-output.png?raw=true)"]},{"metadata":{"id":"DzYe2wPrjM-c","colab_type":"text"},"cell_type":"markdown","source":["# Wymagania\n","\n","Będziesz potrzebował [PyTorch](http://pytorch.org/), aby zbudować i wyszkolić modele, i [matplotlib](https://matplotlib.org/), aby wykreślić postęp treningu, a później zwizualizować wyniki koncentracji."]},{"metadata":{"id":"HapeGWyXjM-e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import unicodedata\n","import string\n","import re\n","import random\n","import time\n","import datetime\n","import math\n","import socket\n","hostname = socket.gethostname()\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from masked_cross_entropy import *\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import matplotlib as mpl\n","import numpy as np\n","# %matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qk60_vl_jM-h","colab_type":"text"},"cell_type":"markdown","source":["Tutaj również zdefiniujemy stałą, aby zdecydować, czy użyć GPU (w szczególności z CUDA), czy procesora. **Jeśli nie masz GPU, ustaw tę wartość na `False`**. Później, kiedy stworzymy tensory, zmienna ta będzie używana do decydowania o tym, czy zachowamy je na procesorze, czy przeniesiemy na GPU."]},{"metadata":{"id":"TXlXt0dGjM-h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["USE_CUDA = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FCNzsA7ujM-k","colab_type":"text"},"cell_type":"markdown","source":["# Ładowanie plików danych\n","\n","Dane do tego projektu to zbiór wielu tysięcy par tłumaczeń z angielskiego na polski.\n","\n","[To pytanie na temat Open Data Stack Exchange](http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages) kieruje na serwis ze zbiorem tłumaczeń http://tatoeba.org/ który ma pliki do pobrania dostępne na stronie http://tatoeba.org/eng/downloads - a dodatkowo, ktoś wykonał pracę polegającą na podzieleniu par językowych na poszczególne pliki tekstowe tutaj: http://www.manythings.org/anki/\n","\n","Potrzebny angielsko-polski plik pobierz używając naszego notebooka konfiguracyjnego. Plik składa się z oddzielonych tabulatorami par tłumaczeń:\n","\n","```\n","The cat is black.     Kot jest czarny.\n","```"]},{"metadata":{"id":"DJoHRQsMjM-k","colab_type":"text"},"cell_type":"markdown","source":["Podobnie jak w przypadku kodowania znakowego, używanego w tutorialach \"char-rnn-\\*\", będziemy reprezentować każde słowo w języku jako wektor *1 z n* (ang. one-hot), czyli gigantyczny wektor zer, z wyjątkiem jednej jedynki (na indeksie słowa). W porównaniu z kilkoma dziesiątkami liter, które mogą istnieć w języku, słów istnieje o wiele wiele więcej, więc i wektor kodowania jest znacznie większy. Trochę jednak oszukamy i strymujemy dane, aby użyć tylko kilku tysięcy słów na język."]},{"metadata":{"id":"eVdtUNzxjM-l","colab_type":"text"},"cell_type":"markdown","source":["### Indeksowanie słów\n","\n","Będziemy potrzebować unikalny indeks dla każdego słowa, który później posłuży jako dane wejściowe i wyjściowe. Aby śledzić to wszystko, użyjemy klasę pomocniczą o nazwie `Lang`, która ma słowniki słowo &rarr; indeks (`word2index`) i indeks &rarr; słowo (`index2word`), a także licznik każdego słowa `word2count`, który można użyć do późniejszego zastąpienia rzadko występujących słów."]},{"metadata":{"id":"38CWcoJijM-m","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["PAD_token = 0\n","SOS_token = 1\n","EOS_token = 2\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n","        self.n_words = 3 # Count default tokens\n","\n","    def index_words(self, sentence):\n","        for word in sentence.split(' '):\n","            self.index_word(word)\n","\n","    def index_word(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    # Remove words below a certain count threshold\n","    def trim(self, min_count):\n","        if self.trimmed: return\n","        self.trimmed = True\n","        \n","        keep_words = []\n","        \n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words %s / %s = %.4f' % (\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Reinitialize dictionaries\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n","        self.n_words = 3 # Count default tokens\n","\n","        for word in keep_words:\n","            self.index_word(word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MrjDYa90jM-o","colab_type":"text"},"cell_type":"markdown","source":["### Czytanie i dekodowanie plików\n","\n","Wszystkie pliki są w Unicode, dla uproszczenia robimy wszystko małymi literami i wycinamy większość znaków interpunkcyjnych."]},{"metadata":{"id":"y-uANRyqjM-p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Lowercase, trim, and remove non-letter characters\n","def normalize_string(s):\n","    s = s.lower().strip()\n","    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","  \n","normalize_string('ala ma kota ąćęłńóśźż ĄĆĘŁŃÓŚŹŻ')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L3_B-7AgjM-r","colab_type":"text"},"cell_type":"markdown","source":["Aby odczytać plik danych, podzielimy go na linie, a następnie podzielimy linie na pary. Wszystkie pliki są \"angielski  &rarr; inny język\", więc jeśli chcemy przetłumaczyć z innego języka &rarr; angielski, dodana została flaga `reverse`, aby odwrócić pary."]},{"metadata":{"id":"Be5PbEG6jM-r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def read_langs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    filename = 'data/seq2seq/%s-%s.txt' % (lang1, lang2)\n","    lines = open(filename).read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gbR0LICajM-u","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["MIN_LENGTH = 3\n","MAX_LENGTH = 25\n","# MIN_LENGTH = 1\n","# MAX_LENGTH = 100\n","\n","def filter_pairs(pairs):\n","    filtered_pairs = []\n","    for pair in pairs:\n","        if len(pair[0]) >= MIN_LENGTH and len(pair[0]) <= MAX_LENGTH \\\n","            and len(pair[1]) >= MIN_LENGTH and len(pair[1]) <= MAX_LENGTH:\n","                filtered_pairs.append(pair)\n","    return filtered_pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3d4PanL1jM-x","colab_type":"text"},"cell_type":"markdown","source":["Pełny proces przygotowywania danych to:\n","\n","* Odczytaj plik tekstowy i podziel na linie, \n","* Podziel linie na pary i znormalizuj, \n","* Przefiltruj do par o maksymalnej długości\n","* Stwórz listy słów ze zdań w parach"]},{"metadata":{"id":"gMHfcrOhjM-x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def prepare_data(lang1_name, lang2_name, reverse=False):\n","    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n","    print(\"Read %d sentence pairs\" % len(pairs))\n","    \n","    pairs = filter_pairs(pairs)\n","    print(\"Filtered to %d pairs\" % len(pairs))\n","    \n","    print(\"Indexing words...\")\n","    for pair in pairs:\n","        input_lang.index_words(pair[0])\n","        output_lang.index_words(pair[1])\n","    \n","    print('Indexed %d words in input language, %d words in output' % (input_lang.n_words, output_lang.n_words))\n","    return input_lang, output_lang, pairs\n","\n","input_lang, output_lang, pairs = prepare_data('eng', 'pol', False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BjKDGSYHjM-2","colab_type":"text"},"cell_type":"markdown","source":["### Filtrowanie słowników\n","\n","Aby coś wytrenować w krócej niż godzinę, strymujmy nieco zestaw danych. Najpierw użyjemy funkcję `trim` w każdym języku (zdefiniowaną wcześniej), aby zachować tylko słowa, które powtarzają się przynajmniej pewną liczbę razy w zestawie danych (co zmniejszy trudność nauczenia się poprawnego tłumaczenia słów, które nie występują często)."]},{"metadata":{"id":"L8uPxAvUjM-2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["MIN_COUNT = 3  # 5\n","# MIN_COUNT = 2\n","\n","input_lang.trim(MIN_COUNT)\n","output_lang.trim(MIN_COUNT)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_batj5qjjM-5","colab_type":"text"},"cell_type":"markdown","source":["### Filtrowanie par\n","\n","Teraz wrócimy do zbioru wszystkich par zdań i usuniemy te z nieznanymi słowami."]},{"metadata":{"id":"3Ht7UIxjjM-6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["keep_pairs = []\n","\n","for pair in pairs:\n","    input_sentence = pair[0]\n","    output_sentence = pair[1]\n","    keep_input = True\n","    keep_output = True\n","    \n","    for word in input_sentence.split(' '):\n","        if word not in input_lang.word2index:\n","            keep_input = False\n","            break\n","\n","    for word in output_sentence.split(' '):\n","        if word not in output_lang.word2index:\n","            keep_output = False\n","            break\n","\n","    # Remove if pair doesn't match input and output conditions\n","    if keep_input and keep_output:\n","        keep_pairs.append(pair)\n","\n","print(\"Trimmed from %d pairs to %d, %.4f of total\" % (len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","pairs = keep_pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KBXR6h89jM-9","colab_type":"text"},"cell_type":"markdown","source":["## Zamiana danych treningowych na Tensory\n","\n","Aby trenować, musimy przekształcić zdania w coś, co sieć neuronowa może zrozumieć, co oczywiście oznacza liczby. Każde zdanie zostanie podzielone na słowa i przekształcone w Tensor, gdzie każde słowo zostanie zastąpione indeksem (z wcześniej przygotowanych indeksów językowych). Podczas tworzenia tych tensorów dodamy również token EOS, aby zasygnalizować, że zdanie jest skończone.\n","\n","![](https://i.imgur.com/LzocpGH.png)"]},{"metadata":{"id":"wtOXR7IkjM--","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Return a list of indexes, one for each word in the sentence, plus EOS\n","def indexes_from_sentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d4cwKAbhjM_D","colab_type":"text"},"cell_type":"markdown","source":["Możemy lepiej wykorzystać GPU, trenując **wsady** (ang. batches) wielu sekwencji naraz, ale czyniąc to, pojawia się pytanie, jak radzić sobie z sekwencjami o różnych długościach. Prostym rozwiązaniem jest \"dopełnienie\" (ang. padding) krótszych zdań pewnym symbolem dopełnienia (w tym przypadku `0`) i ignorowanie tych dopełnionych miejsc podczas obliczania straty.\n","\n","![](https://i.imgur.com/gGlkEEF.png)"]},{"metadata":{"id":"X_n5XY_wjM_D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Pad a with the PAD symbol\n","def pad_seq(seq, max_length):\n","    seq += [PAD_token for i in range(max_length - len(seq))]\n","    return seq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hjbE-NkajM_F","colab_type":"text"},"cell_type":"markdown","source":["Aby utworzyć zmienną dla pełnego wsadu wejść (i docelowych wyjść), pobieramy losową próbkę sekwencji i dopełniamy je wszystkie do długości najdłuższej sekwencji. Będziemy śledzić długości wszystkich wsadów, aby później usunąć dopełnienie.\n","\n","Inicjowanie `LongTensor` za pomocą tablicy (wsadów) tablic (sekwencyj) daje nam  `(batch_size x max_len)` tensor - wybór pierwszego wymiaru daje pojedynczy element, który jest pełną sekwencją. Podczas szkolenia modelu będziemy potrzebować jednego kroku naraz, więc przetransponujmy go do `(max_len x batch_size)`. Teraz wybieranie wzdłuż pierwszego wymiaru zwraca jeden krok poprzez wsad.\n","\n","\n","![](https://github.com/wojtekcz/ml_seminars/blob/master/wyklad_nmt/images2/batch-transpose.png?raw=true)"]},{"metadata":{"id":"QV-eXwgPjM_G","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def random_batch(batch_size):\n","    input_seqs = []\n","    target_seqs = []\n","\n","    # Choose random pairs\n","    for i in range(batch_size):\n","        pair = random.choice(pairs)\n","        input_seqs.append(indexes_from_sentence(input_lang, pair[0]))\n","        target_seqs.append(indexes_from_sentence(output_lang, pair[1]))\n","\n","    # Zip into pairs, sort by length (descending), unzip\n","    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n","    input_seqs, target_seqs = zip(*seq_pairs)\n","    \n","    # For input and target sequences, get array of lengths and pad with 0s to max length\n","    input_lengths = [len(s) for s in input_seqs]\n","    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n","    target_lengths = [len(s) for s in target_seqs]\n","    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n","\n","    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n","    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n","    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n","    \n","    if USE_CUDA:\n","        input_var = input_var.cuda()\n","        target_var = target_var.cuda()\n","        \n","    return input_var, input_lengths, target_var, target_lengths"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4mFgcJcnjM_I","colab_type":"text"},"cell_type":"markdown","source":["Możemy przetestować to, aby zobaczyć, że zwróci on tensor `(max_len x batch_size)` dla zdań źródłowych i docelowych, wraz z odpowiadającą im listą długości sekwencji (które wykorzystamy później do maskowania)."]},{"metadata":{"id":"SRQMhAnnjM_J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["random_batch(2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YKx3SlwgjM_K","colab_type":"text"},"cell_type":"markdown","source":["# Budowanie modeli"]},{"metadata":{"id":"LFIBysF3jM_L","colab_type":"text"},"cell_type":"markdown","source":["## Koder\n","\n","<img src=\"https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/images/encoder-network.png?raw=true\" style=\"float: right\" />\n","\n","Koder pobierze wsad sekwencji słów, `LongTensor` o rozmiarze `(max_len x batch_size)` i odda kodowanie dla każdego słowa, `FloatTensor` o rozmiarze `(max_len x batch_size x hidden_size)`.\n","\n","Słowne dane wejściowe są podawane przez [warstwę osadzającą `nn.Embedding`](http://pytorch.org/docs/nn.html#embedding) w celu utworzenia osadzenia dla każdego słowa, o rozmiarze `seq_len x hidden_size` (jakby to był wsad słów). Jest to zmieniane na `seq_len x 1 x hidden_size`, aby pasowało do oczekiwanego wejścia [warstwy GRU` nn.GRU`](http://pytorch.org/docs/nn.html#gru). GRU zwróci zarówno sekwencję wyjściową o rozmiarze `seq_len x hidden_size` jak i ukryty stan.\n","\n"]},{"metadata":{"id":"CWtfwbnwjM_M","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n","        super(EncoderRNN, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","        \n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n","        \n","    def forward(self, input_seqs, input_lengths, hidden=None):\n","        # Note: we run this all at once (over multiple batches of multiple sequences)\n","        embedded = self.embedding(input_seqs)\n","        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        outputs, hidden = self.gru(packed, hidden)\n","        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n","        return outputs, hidden"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BLWVsv1VjM_O","colab_type":"text"},"cell_type":"markdown","source":["## Dekoder z koncentracją"]},{"metadata":{"id":"yHtNHu50jM_O","colab_type":"text"},"cell_type":"markdown","source":["### Interpretacja modelu Bahdanau\n","\n","Publikacja [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) (Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio) wprowadziła ideę użycia koncentracji przy tłumaczeniu seq2seq.\n","\n","Każde wyjście dekodera jest uwarunkowane poprzednimi wyjściami i pewnym $\\mathbf x$, gdzie $\\mathbf x $składa się z bieżącego stanu ukrytego (który bierze pod uwagę poprzednie wyjścia) i \"kontekstu\" koncentracji, który jest obliczany poniżej. Funkcja $g$ jest w pełni połączoną warstwą z nieliniową aktywacją, która jako dane wejściowe przyjmuje połączone wartości $y_{i-1}$, $s_i$ i $c_i$.\n","\n","\n","$$\n","p(y_i \\mid \\{y_1,...,y_{i-1}\\},\\mathbf{x}) = g(y_{i-1}, s_i, c_i)\n","$$\n","\n","Bieżący stan ukryty $s_i$ jest obliczany przez RNN $f$ z ostatnim ukrytym stanem $s_{i-1}$, ostatnią wartością wyjściową dekodera $y_{i-1}$  i wektorem kontekstu $c_i$.\n","W kodzie RNN będzie warstwą `nn.GRU`, ukryty stan $s_i$ będzie nazywany `hidden`, wyjście $y_i$ zwane `output` oraz kontekst $c_i$ zwany `context`.\n","\n","\n","$$\n","s_i = f(s_{i-1}, y_{i-1}, c_i)\n","$$\n","\n","Wektor kontekstu $c_i$ jest sumą ważoną wszystkich wyników kodera, gdzie każda waga $a_{ij}$ jest ilością \"koncentracji\" przekazanej na odpowiednie wyjście kodera $h_j$.\n","\n","\n","$$\n","c_i = \\sum_{j=1}^{T_x} a_{ij} h_j\n","$$\n","\n","... gdzie każda waga $a_{ij}$ to znormalizowana (poprzez wszystkie kroki) \"energia\" koncentracji $e_{ij}$ ...\n","\n","$$\n","a_{ij} = \\dfrac{exp(e_{ij})}{\\sum_{k=1}^{T} exp(e_{ik})}\n","$$\n","\n","... gdzie każda energia koncentracji jest obliczana za pomocą funkcji $a$ (takiej jak inna warstwa liniowa) przy użyciu ostatniego ukrytego stanu $s_{i-1}$ i tego konkretnego wyjścia kodera $h_j$:\n","\n","$$\n","e_{ij} = a(s_{i-1}, h_j)\n","$$"]},{"metadata":{"id":"tVGfY39sjM_O","colab_type":"text"},"cell_type":"markdown","source":["### Interpretacja modelu Luonga"]},{"metadata":{"id":"079wjeknjM_P","colab_type":"text"},"cell_type":"markdown","source":["[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) autorstwa Luonga i innych opisuje kilka modeli koncentracji, które oferują ulepszenia i uproszczenia. Autorzy opisują kilka modeli \"globalnej koncentracji\", rozróżnianych przez sposób obliczania wyników koncentracji.\n","\n","Ogólna forma obliczania koncentracji opiera się na ukrytym stanie po stronie docelowej (dekodera) i odpowiednim stanie bocznym źródła (kodera), znormalizowanym dla wszystkich stanów, aby uzyskać wartości zsumowane do 1:\n","\n","$$\n","a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n","$$\n","\n","Konkretną funkcją \"oceny\" (score), która porównuje dwa stany, jest albo *dot*, iloczyn skalarny między stanami; *general*, iloczyn skalarny między ukrytym stanem dekodera a liniową transformacją stanu kodera; lub *concat*, iloczyn skalarny między nowym parametrem $v_a$ a liniową transformacją stanów połączonych ze sobą.\n","\n","\n","$$\n","score(h_t, \\bar h_s) =\n","\\begin{cases}\n","h_t ^\\top \\bar h_s & dot \\\\\n","h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n","v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n","\\end{cases}\n","$$\n","\n","Modularna definicja tych funkcji ewaluacji daje nam możliwość zbudowania specjalnego modułu koncentracji, który może przełączać się między różnymi metodami oceny. Wejście do tego modułu to zawsze stan ukryty (dekodera RNN) i zestaw wyjść kodera.\n"]},{"metadata":{"id":"8tvHPEhbjM_Q","colab_type":"text"},"cell_type":"markdown","source":["### Implementacja modułu koncentracji"]},{"metadata":{"id":"tvQQ9_O6jM_Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Attn(nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        \n","        self.method = method\n","        self.hidden_size = hidden_size\n","        \n","        if self.method == 'general':\n","            self.attn = nn.Linear(self.hidden_size, hidden_size)\n","\n","        elif self.method == 'concat':\n","            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n","\n","    def forward(self, hidden, encoder_outputs):\n","        max_len = encoder_outputs.size(0)\n","        this_batch_size = encoder_outputs.size(1)\n","\n","        # Create variable to store attention energies\n","        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n","\n","        if USE_CUDA:\n","            attn_energies = attn_energies.cuda()\n","\n","        # For each batch of encoder outputs\n","        for b in range(this_batch_size):\n","            # Calculate energy for each encoder output\n","            for i in range(max_len):\n","                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n","\n","        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n","        return F.softmax(attn_energies, dim=-1).unsqueeze(1)\n","    \n","    def score(self, hidden, encoder_output):\n","        if self.method == 'dot':\n","            energy =torch.dot(hidden.view(-1), encoder_output.view(-1))\n","        elif self.method == 'general':\n","            energy = self.attn(encoder_output)\n","            energy = torch.dot(hidden.view(-1), energy.view(-1))\n","        elif self.method == 'concat':\n","            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n","            energy = torch.dot(self.v.view(-1), energy.view(-1))\n","        return energy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CdQV7jCLjM_R","colab_type":"text"},"cell_type":"markdown","source":["### Implementacja modelu Bahdanau\n","\n","Podsumowując, nasz dekoder powinien składać się z czterech głównych części - warstwy osadzającej, zamieniającej słowo wejściowe w wektor; warstwy do obliczenia energii koncentracji na wyjście kodera; warstwy RNN; i warstwt wyjściowej.\n","\n","Wejścia dekodera to ostatni ukryty stan RNN $s_{i-1}$, ostatnie wyjście $y_{i-1}$ oraz wszystkie wyjścia kodera $h_*$.\n","\n","* warstwa osadzająca z wejściami $y_{i-1}$\n","    * `embedded = embedding(last_rnn_output)`\n","* warstwa koncentracji $a$ z wejściami $(s_{i-1}, h_j)$ i wyjściami $e_{ij}$, znormalizowanymi w celu utworzenia $a_{ij}$\n","    * `attn_energies[j] = attn_layer(last_hidden, encoder_outputs[j])`\n","    * `attn_weights = normalize(attn_energies)`\n","* wektor kontekstowy $c_i$ jako średnia ważona wyjść kodera\n","    * `context = sum(attn_weights * encoder_outputs)`\n","* warstwa (warstwy) RNN $f$ z wejściami $(s_{i-1}, y_{i-1}, c_i)$ i wewnętrznym stanem ukrytym, oddaje $s_i$\n","    * `rnn_input = concat(embedded, context)`\n","    * `rnn_output, rnn_hidden = rnn(rnn_input, last_hidden)`\n","* warstwa wyjściowa $g$ z wejściami $(y_{i-1}, s_i, c_i)$, oddaje $y_i$\n","    * `output = out(embedded, rnn_output, context)`\n","\n"]},{"metadata":{"id":"Cq2AurVKjM_S","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class BahdanauAttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n","        super(BahdanauAttnDecoderRNN, self).__init__()\n","        \n","        # Define parameters\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","        \n","        # Define layers\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.attn = Attn('concat', hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n","        self.out = nn.Linear(hidden_size, output_size)\n","    \n","    def forward(self, word_input, last_hidden, encoder_outputs):\n","        # Note: we run this one step at a time\n","        # TODO: FIX BATCHING\n","        \n","        # Get the embedding of the current input word (last output word)\n","        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n","        word_embedded = self.dropout(word_embedded)\n","        \n","        # Calculate attention weights and apply to encoder outputs\n","        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n","        context = context.transpose(0, 1) # 1 x B x N\n","        \n","        # Combine embedded input word and attended context, run through RNN\n","        rnn_input = torch.cat((word_embedded, context), 2)\n","        output, hidden = self.gru(rnn_input, last_hidden)\n","        \n","        # Final output layer\n","        output = output.squeeze(0) # B x N\n","        output = F.log_softmax(self.out(torch.cat((output, context), 1)), dim=-1)\n","        \n","        # Return final output, hidden state, and attention weights (for visualization)\n","        return output, hidden, attn_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qq9r0senjM_U","colab_type":"text"},"cell_type":"markdown","source":["Teraz możemy zbudować dekoder, który podłącza ten moduł Attn za RNN, aby obliczyć wagi koncentracji, i zastosować te wagi do wyjść kodera, aby uzyskać wektor kontekstu.\n"]},{"metadata":{"id":"8WQ5ZymQjM_U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        \n","        # Choose attention model\n","        if attn_model != 'none':\n","            self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_seq, last_hidden, encoder_outputs):\n","        # Note: we run this one step at a time\n","\n","        # Get the embedding of the current input word (last output word)\n","        batch_size = input_seq.size(0)\n","        embedded = self.embedding(input_seq)\n","        embedded = self.embedding_dropout(embedded)\n","        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n","\n","        # Get current hidden state from input word and last hidden state\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","\n","        # Calculate attention from current RNN state and all encoder outputs;\n","        # apply to encoder outputs to get weighted average\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n","\n","        # Attentional vector using the RNN hidden state and context vector\n","        # concatenated together (Luong eq. 5)\n","        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n","        context = context.squeeze(1)       # B x S=1 x N -> B x N\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = F.tanh(self.concat(concat_input))\n","\n","        # Finally predict next token (Luong eq. 6, without softmax)\n","        output = self.out(concat_output)\n","\n","        # Return final output, hidden state, and attention weights (for visualization)\n","        return output, hidden, attn_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4GlQFiBXjM_W","colab_type":"text"},"cell_type":"markdown","source":["## Testowanie modeli\n","\n","Aby upewnić się, że moduły kodera i dekodera działają (i współpracują ze sobą), wykonamy pełny test przy pomocy małego wsadu."]},{"metadata":{"id":"1Jl3G8A3jM_W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["small_batch_size = 3\n","input_batches, input_lengths, target_batches, target_lengths = random_batch(small_batch_size)\n","\n","print('input_batches', input_batches.size()) # (max_len x batch_size)\n","print('target_batches', target_batches.size()) # (max_len x batch_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eFNjmpOZjM_Z","colab_type":"text"},"cell_type":"markdown","source":["Twórz modele o małym rozmiarze (można je kontrolować wzrokowo):"]},{"metadata":{"id":"nS0S6358jM_c","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["small_hidden_size = 8\n","small_n_layers = 2\n","\n","encoder_test = EncoderRNN(input_lang.n_words, small_hidden_size, small_n_layers)\n","decoder_test = LuongAttnDecoderRNN('general', small_hidden_size, output_lang.n_words, small_n_layers)\n","\n","if USE_CUDA:\n","    encoder_test.cuda()\n","    decoder_test.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yJLRqxZQjM_g","colab_type":"text"},"cell_type":"markdown","source":["Aby przetestować, przepuść przez koder wsad wejściowy, aby uzyskać wyjścia kodera per-wsad:"]},{"metadata":{"id":"_biyc0SPjM_h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n","\n","print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n","print('encoder_hidden', encoder_hidden.size()) # n_layers * 2 x batch_size x hidden_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ambBXpSVjM_m","colab_type":"text"},"cell_type":"markdown","source":["Następnie zaczynając od tokena SOS, przepuść słowne tokeny przez dekoder, aby uzyskać każdy następny token. Zamiast robić to z całą sekwencją, robi się to po jednym tokenie na raz, aby wesprzeć używanie jego własnych prognoz do wykonania następnej prognozy. Będzie to tylko jeden krok, ale obejmujący cały wsad. Aby to zadziałało w przypadku krótkich sekwencji, wielkość wsadu będzie się zmniejszać za każdym razem."]},{"metadata":{"id":"j6Vc_e9fjM_n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["max_target_length = max(target_lengths)\n","\n","# Prepare decoder input and outputs\n","decoder_input = Variable(torch.LongTensor([SOS_token] * small_batch_size))\n","decoder_hidden = encoder_hidden[:decoder_test.n_layers] # Use last (forward) hidden state from encoder\n","all_decoder_outputs = Variable(torch.zeros(max_target_length, small_batch_size, decoder_test.output_size))\n","\n","if USE_CUDA:\n","    all_decoder_outputs = all_decoder_outputs.cuda()\n","    decoder_input = decoder_input.cuda()\n","\n","# Run through decoder one time step at a time\n","for t in range(max_target_length):\n","    decoder_output, decoder_hidden, decoder_attn = decoder_test(\n","        decoder_input, decoder_hidden, encoder_outputs\n","    )\n","    all_decoder_outputs[t] = decoder_output # Store this step's outputs\n","    decoder_input = target_batches[t] # Next input is current target\n","\n","# Test masked cross entropy loss\n","loss = masked_cross_entropy(\n","    all_decoder_outputs.transpose(0, 1).contiguous(),\n","    target_batches.transpose(0, 1).contiguous(),\n","    target_lengths\n",")\n","print('loss', loss.item())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dXDizgVajM_p","colab_type":"text"},"cell_type":"markdown","source":["# Trenowanie\n","\n","## Definiowanie iteracji treningu\n","\n","Aby trenować, najpierw przepuszczamy zdanie wejściowe przez koder słowo po słowie i śledzimy każde wyjście i ostatni stan ukryty. Następnie dekoder otrzymuje ostatni ukryty stan dekodera jako swój pierwszy ukryty stan, a token `<SOS>` jako pierwsze wejście. Następnie iterujemy aby prognozować następny token z dekodera.\n","\n","### \"Teacher Forcing\" kontra Scheduled Sampling\n","\n","\"Teacher Forcing\" lub pobieranie próbek o największej wiarygodności oznacza wykorzystanie rzeczywistych wyników docelowych jako każdego następnego wejścia podczas treningu. Alternatywą jest użycie własnego odgadnięcia przez dekoder jako następnego wejścia. Korzystanie z wymuszania nauczyciela może spowodować szybsze zbieganie się sieci, ale [kiedy wyszkolona sieć jest wykorzystywana, może wykazywać niestabilność](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n","\n","Możesz obserwować wyniki wymuszonych przez nauczyciela sieci, które czytają ze spójną gramatyką, ale oddalają się od prawidłowego tłumaczenia - możesz myśleć o tym, że nauczyłeś się słuchać instrukcji nauczyciela, nie ucząc się samodzielnego wyjścia.\n","\n","Rozwiązanie \"problemu\" teacher-forcing jest znane jako [Zaplanowane próbkowanie (ang. Scheduled Sampling)](https://arxiv.org/abs/1506.03099), które po prostu przełącza się między wartościami docelowymi i prognozowanymi wartościami podczas trenowania. My losowo wybieramy użycie wymuszania nauczyciela instrukcją if podczas treningu - czasami będziemy podawać rzeczywisty cel jako wejście (ignorując wyjście dekodera), czasami użyjemy wyjścia dekodera.\n"]},{"metadata":{"id":"LkxmrG0GjM_q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    \n","    # Zero gradients of both optimizers\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    loss = 0 # Added onto for each word\n","\n","    # Run words through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n","    \n","    # Prepare input and output variables\n","    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n","    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n","\n","    max_target_length = max(target_lengths)\n","    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n","\n","    # Move new Variables to CUDA\n","    if USE_CUDA:\n","        decoder_input = decoder_input.cuda()\n","        all_decoder_outputs = all_decoder_outputs.cuda()\n","\n","    # Run through decoder one time step at a time\n","    for t in range(max_target_length):\n","        decoder_output, decoder_hidden, decoder_attn = decoder(\n","            decoder_input, decoder_hidden, encoder_outputs\n","        )\n","\n","        all_decoder_outputs[t] = decoder_output\n","        decoder_input = target_batches[t] # Next input is current target\n","\n","    # Loss calculation and backpropagation\n","    loss = masked_cross_entropy(\n","        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n","        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n","        target_lengths\n","    )\n","    loss.backward()\n","    \n","    # Clip gradient norms\n","    ec = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    dc = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Update parameters with optimizers\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    \n","    return loss.item(), ec, dc  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"fm2GZxu2jM_s","colab_type":"text"},"cell_type":"markdown","source":["## Uruchamianie treningu\n","\n","Gdy wszystko jest gotowe, możemy zainicjować sieć i rozpocząć trening.\n","\n","Na początek inicjujemy modele, optymalizatory, funkcję straty (kryterium), i ustawiamy zmienne dla kreślenia i śledzenia postępu."]},{"metadata":{"id":"y8QsdydpjM_s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Configure models\n","attn_model = 'dot'\n","hidden_size = 500\n","n_layers = 2\n","dropout = 0.1\n","batch_size = 50 # 1600  # 100\n","# batch_size = 50\n","\n","# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 0.5\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_epochs = 1000 # 50000\n","epoch = 0\n","plot_every = 10\n","print_every = 50  # 100\n","evaluate_every = 50 # 1000\n","\n","# Initialize models\n","encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers, dropout=dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)\n","\n","# Initialize optimizers and criterion\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Move models to GPU\n","if USE_CUDA:\n","    encoder.cuda()\n","    decoder.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mEGr4sQnYXSG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from torchnet.logger import VisdomPlotLogger, VisdomLogger, VisdomTextLogger\n","from tqdm import tqdm\n","import io\n","import json\n","\n","# Start a job\n","\n","class Job:\n","    def __init__(self, name, params={}, hostname='localhost', port=8890, n_epochs=10):\n","        self.name = name\n","        self.params = params\n","        self.hostname = hostname\n","        self.port = port\n","        self.avg_train_loss_logger = VisdomPlotLogger(\n","        'line', port=port, opts={'title': f'{name}_Train Loss'})\n","        self.job_logger = VisdomTextLogger(port=port, opts={'title': f'{name}_Job Info'})\n","        self.log_logger = VisdomTextLogger(port=port, opts={'title': f'{name}_Train Loss Log'}, update_type='APPEND')\n","        self.pbar = tqdm(total=n_epochs, ncols=60, mininterval=1.0, ascii=True, file=io.StringIO())\n","        self.progress_logger = VisdomTextLogger(port=port, opts=dict(title=f'{name}_Progress Bar',\n","            width=500,\n","            height=50,\n","        ))\n","\n","        self.start()\n","\n","    def start(self):\n","        j_str = json.dumps(self.params, indent=4)\n","        j_str = j_str.replace('\\n', '<br/>\\n').replace(' ', '&nbsp;')\n","        self.job_logger.log(f'{j_str}')\n","\n","        self.job_id = '#job_id'# body['id']\n","        print(\"Starting job %s at %s\" % (self.job_id, time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())))\n","        self.start_time = time.time()\n","\n","        self.log_every = 50\n","        self.plot_every = 50\n","        self.loss_avg = 0\n","\n","    def stop(self, ):\n","        j = {'status': 'done'}\n","        print(j)\n","\n","    def log(self, l):\n","        def time_since(since):\n","            now = time.time()\n","            s = now - since\n","            m = math.floor(s / 60)\n","            s -= m * 60\n","            return '%dm %ds' % (m, s)\n","        self.log_logger.log(l)\n","\n","    def plot(self, x, y):\n","        self.avg_train_loss_logger.log(x, y)\n","\n","    def record(self, e, loss):\n","        self.loss_avg += loss\n","\n","        if e > 0 and e % self.log_every == 0:\n","            self.log('(%s) %.4f' % (e, loss))\n","\n","        if e > 0 and e % self.plot_every == 0:\n","            self.plot(e, self.loss_avg / self.plot_every)\n","            self.loss_avg = 0\n","\n","    def update_progress(self, ):\n","        self.pbar.update(1)\n","        text = f'{self.pbar}'.replace(' ', '<font color=\"white\">#</font>')\n","        self.progress_logger.log(text)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N2cXAJPC-Epg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["job = Job('seq2seq-translate', {\n","    'attn_model': attn_model,\n","    'n_layers': n_layers,\n","    'dropout': dropout,\n","    'hidden_size': hidden_size,\n","    'learning_rate': learning_rate,\n","    'clip': clip,\n","    'teacher_forcing_ratio': teacher_forcing_ratio,\n","    'decoder_learning_ratio': decoder_learning_ratio,\n","}, n_epochs=n_epochs)\n","job.plot_every = plot_every\n","job.log_every = print_every\n","\n","# Keep track of time elapsed and running averages\n","start = time.time()\n","plot_losses = []\n","print_loss_total = 0 # Reset every print_every\n","plot_loss_total = 0 # Reset every plot_every\n","\n","import visdom\n","\n","vis = visdom.Visdom(port=job.port)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MDT8rrLFjM_u","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def as_minutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def time_since(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vMjoLgjRjM_v","colab_type":"text"},"cell_type":"markdown","source":["# Ewaluacja sieci\n","\n","Ewaluacja jest w większości taka sama jak trening, z tym że bez danych docelowych. Zamiast tego zawsze podajemy prognozy dekodera z powrotem do niego. Za każdym razem, gdy prognozuje słowo, dodajemy je do łańcucha wyjściowego. Jeśli dekoder prognozuje token EOS, kończymy. Przechowujemy także wyniki koncentracji dekodera dla każdego kroku, aby je później wyświetlić.\n"]},{"metadata":{"id":"cZyepm7XjM_v","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def evaluate(input_seq, max_length=MAX_LENGTH):\n","    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n","    input_lengths = [len(input_seqs[0])]\n","\n","    input_batches = Variable(torch.LongTensor(input_seqs)).transpose(0, 1)\n","\n","    if USE_CUDA:\n","        input_batches = input_batches.cuda()\n","\n","    # Set to not-training mode to disable dropout\n","    encoder.train(False)\n","    decoder.train(False)\n","\n","    # Run through encoder\n","    with torch.no_grad():\n","        encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n","\n","    # Create starting vectors for decoder\n","    decoder_input = Variable(torch.LongTensor([SOS_token])) # SOS\n","    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n","\n","    if USE_CUDA:\n","        decoder_input = decoder_input.cuda()\n","\n","    # Store output words and attention states\n","    decoded_words = []\n","    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n","\n","    # Run through decoder\n","    for di in range(max_length):\n","        with torch.no_grad():\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n","\n","        # Choose top word from output\n","        topv, topi = decoder_output.data.topk(1)\n","        ni = topi[0][0]\n","        if ni == EOS_token:\n","            decoded_words.append('<EOS>')\n","            break\n","        else:\n","            decoded_words.append(output_lang.index2word[ni.item()])\n","\n","        # Next input is chosen word\n","        decoder_input = Variable(torch.LongTensor([ni]))\n","        if USE_CUDA: decoder_input = decoder_input.cuda()\n","\n","    # Set back to training mode\n","    encoder.train(True)\n","    decoder.train(True)\n","    \n","    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kyY9aX0mjM_y","colab_type":"text"},"cell_type":"markdown","source":["Możemy oceniać losowo wybrane zdania z zestawu treningowego i wyświetlić dane wejściowe, docelowe i wyjściowe w celu dokonania subiektywnej oceny jakości:"]},{"metadata":{"id":"CpGS1t6AjM_z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def evaluate_randomly():\n","    [input_sentence, target_sentence] = random.choice(pairs)\n","    evaluate_and_show_attention(input_sentence, target_sentence)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MVBji1kAjM_1","colab_type":"text"},"cell_type":"markdown","source":["# Wizualizacja koncentracji\n","\n","Użyteczną właściwością mechanizmu koncentracji są jego wysoce interpretowalne wyniki. Ponieważ jest on używany do \"ważenia\" poszczególnych wyjść kodera dla sekwencji wejściowej, możemy sobie wyobrazić, na czym sieć skupia się w każdym kroku.\n","\n","Możesz po prostu wywołać `plt.matshow(attentions)`, aby zobaczyć wyniki koncentracji wyświetlone jako matryca, z kolumnami będącymi krokami wejściowymi i wierszami będącymi krokami wyjściowymi:"]},{"metadata":{"id":"73IB60mJjM_1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import io\n","import torchvision\n","from PIL import Image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-M099fekjM_3","colab_type":"text"},"cell_type":"markdown","source":["Aby uzyskać lepszy efekt wizualny, dodamy osie i etykiety:"]},{"metadata":{"id":"vM8VYNy5d-BX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def show_plot_visdom():\n","    buf = io.BytesIO()\n","    plt.savefig(buf)\n","    buf.seek(0)\n","    attn_win = 'attention (%s)' % hostname\n","    vis.image(torchvision.transforms.ToTensor()(Image.open(buf)), win=attn_win, opts={'title': attn_win})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bjgNvhWrjM_3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def show_attention(input_sentence, output_words, attentions):\n","    mpl.style.use('default')\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)    \n","    cax = ax.matshow(attentions.numpy(), cmap='jet')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    show_plot_visdom()\n","    plt.show()\n","    plt.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"46Dts5BjjM_5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def evaluate_and_show_attention(input_sentence, target_sentence=None):\n","    output_words, attentions = evaluate(input_sentence)\n","    output_sentence = ' '.join(output_words)\n","    print('>', input_sentence)\n","    if target_sentence is not None:\n","        print('=', target_sentence)\n","    print('<', output_sentence)\n","    \n","    show_attention(input_sentence, output_words, attentions)\n","    \n","    # Show input, target, output text in visdom\n","    win = 'evaluted (%s)' % hostname\n","    text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n","    vis.text(text, win=win, opts={'title': win})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4-BmvDLCjM_6","colab_type":"text"},"cell_type":"markdown","source":["# Składamy wszystko razem"]},{"metadata":{"id":"od07gsWkjM_7","colab_type":"text"},"cell_type":"markdown","source":["Żeby przeprowadzić właściwy trening, wielokrotnie wywołujemy funkcję treningową i wyświetlamy podsumowanie w trakcie.\n","\n","*Zauważ:* w trakcie pracy z tyme notatnikiem możesz **trenować, przerywać, ewaluować i wracać tutaj, by kontynuować trening**. Po prostu wykonaj pozostałą część notatnika zaczynając od następnej komórki (wykonanie od poprzedniej komórki zresetuje modele)."]},{"metadata":{"id":"0ahWiXo5jM_7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1522},"outputId":"e9515e3b-fc37-419f-daf3-818b70caf781"},"cell_type":"code","source":["# Begin!\n","ecs = []\n","dcs = []\n","eca = 0\n","dca = 0\n","\n","while epoch < n_epochs:\n","    epoch += 1\n","    \n","    # Get training data for this cycle\n","    input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n","\n","    # Run the train function\n","    loss, ec, dc = train(\n","        input_batches, input_lengths, target_batches, target_lengths,\n","        encoder, decoder,\n","        encoder_optimizer, decoder_optimizer, criterion\n","    )\n","\n","    # Keep track of loss\n","    print_loss_total += loss\n","    plot_loss_total += loss\n","    eca += ec\n","    dca += dc\n","    \n","    job.record(epoch, loss)\n","    job.update_progress()\n","\n","    if epoch % print_every == 0:\n","        print(f'{job.pbar}')\n","        print_loss_avg = print_loss_total / print_every\n","        print_loss_total = 0\n","        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n","        print(print_summary)\n","        \n","    if epoch % evaluate_every == 0:\n","        evaluate_randomly()\n","\n","    if epoch % plot_every == 0:\n","        plot_loss_avg = plot_loss_total / plot_every\n","        plot_losses.append(plot_loss_avg)\n","        plot_loss_total = 0\n","        \n","        # TODO: Running average helper\n","        ecs.append(eca / plot_every)\n","        dcs.append(dca / plot_every)\n","        ecs_win = 'encoder grad (%s)' % hostname\n","        dcs_win = 'decoder grad (%s)' % hostname\n","        vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n","        vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n","        eca = 0\n","        dca = 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 10%|#8                 | 98/1000 [1:01:33<44:07,  2.94s/it]\n","61m 32s (- 553m 56s) (100 10%) 3.5083\n","> i'm bored .\n","= nudzę się .\n","< jestem . <EOS>\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAikAAAGnCAYAAABywccrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7fa5e5e51d30>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":[" 15%|##6               | 148/1000 [1:03:55<41:12,  2.90s/it]\n","63m 55s (- 362m 14s) (150 15%) 3.1839\n","> nice to see you .\n","= miło cię widzieć .\n","< musisz cię . <EOS>\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAikAAAGWCAYAAAC95xMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7fa5e5df36a0>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":[" 20%|###5              | 198/1000 [1:06:20<38:39,  2.89s/it]\n","66m 20s (- 265m 21s) (200 20%) 2.8810\n","> how much does it cost ?\n","= ile kosztuje ?\n","< jak to jest ? <EOS>\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAikAAAGgCAYAAABvxPeTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XlcVXX+x/E3XATcwBVwYUIt9zVN\nQzO1KJ1Kf05lZrnmkpYrNamlotWEU42pUzOWZdrkVlaOpaFJYuNSzrhU5pZbogZuBSoKci+/P4xb\nN6CAA5xz7n09H4/zmDicc8/nPJq8Hz+fz/ccv5ycnBwBAABYjL/ZAQAAAOSHJAUAAFgSSQoAALAk\nkhQAAGBJJCkAAMCSSFIAAIAlkaQAAABLIkkBAACWRJICAAAsiSQFAABYEkkKAACwJJIUAABgSSQp\nAADAkkhSAABexel06quvvlJ2drbZocAgkhQAgFf58MMP1aZNGy1fvtzsUGAQSQoAwKssWrRINWvW\n1MKFC80OBQb55eTk5JgdBAAAJeHMmTOqW7euVq5cqV69eunw4cOqW7eu2WGhmKikAAC8xtKlS9W8\neXP16NFDnTt31r/+9S+zQ4IBJCkAAK+xcOFCDRw4UJLUv39/vfXWWyZHBCNo9wAAvMLu3bvVtm1b\nnThxQjVq1NCFCxcUHh6uTz/9VB06dDA7PBQDlRQAgFdYtGiRbr/9dtWoUUOSVKlSJfXu3ZsBWhsj\nSQEA2J7T6dTbb7/tbvXk6t+/v5YvX66srCyTIoMRjunTp083OwgAAIxITU2Vv7+/hg0bJofD4d7f\noEEDZWdnq0GDBgoNDTUxQhQHMykAAMCSaPcAALzSd999pz179sjlcpkdCoqJJAUAYGsLFizQrFmz\nPPaNGDFC9evXV4sWLdS8eXMlJyebFB2MoN2DMvHtt99qw4YNOnXqVJ6/1UybNs2kqAB4gxtvvFEP\nP/ywhgwZIklKSEhQz549tXDhQjVp0kSjR49W06ZN9frrr5scqXGXL18ukSHgwMBABQcHl0BEpYsk\nBaVu/vz5GjVqlGrUqKGIiAj5+fm5f+fn56cdO3aYGB0Au6tevbqSkpLUokULSdKoUaN0+vRprVix\nQpKUlJSkIUOG6MiRI2aGadjly5dVs3x5XSiBz4qIiNCRI0csn6gEmB0AvN+zzz6rv/zlL5o4caLZ\noQDwQpcuXVJISIj75y1btmjo0KHun+vXr6+UlBQzQitRWVlZuiBpgqQgA5+TKemllBRlZWWRpAA/\n/PCD+vTpY3YYALzUNddco+3bt+uaa67RmTNn9M0336hTp07u36ekpHjV8uOKkoykFnb64mdwFqWu\nT58+WrdundlhlJn09HStXLlSe/fuNTsUwCcMGjRIjz76qJ555hn16dNHjRs3Vtu2bd2/37Jli5o3\nb25ihCWrXAlsdmGnhAo2MnfuXPc/X3vttZo6dao+//xztWjRQuXKef4nMnbs2LIOr0Tdd999uvnm\nmzV69GhdunRJ7dq109GjR5WTk6Nly5bpnnvuMTtEwKs98cQTysjI0Pvvv6+IiAi9++67Hr/fvHmz\n+vXrZ1J0MILBWZSKevXqFeo4Pz8/HT58uJSjKV0RERFau3atWrVqpSVLliguLk5ffvmlFi1apNde\ne007d+40O0QAXiA9PV2hoaH6i4y1ey5LekpSWlqaxyyPFVFJQamw+xR9UaSlpalatWqSri59vOee\ne1ShQgXdeeed+vOf/2xydIDvuHTpkj755BMdOHBAktSwYUPddtttKl++vMmRlawAGWvZZJdUIGWA\nJAUwKDIyUlu3blW1atWUkJCgZcuWSbo6MGz1yXlc9dZbb6lv374KCvJcM5GVlaVly5bleWkdrGfV\nqlUaNmyYzpw547G/Ro0aeuONN9SzZ0+TIoMRDM6i1N1zzz3661//mmf/888/7xWrfsaPH68HH3xQ\ndevWVa1atdS1a1dJ0meffeZ+bgOsbciQIUpLS8uz//z58+4HhMG6tmzZonvvvVc333yzNm/erHPn\nzuncuXPatGmTOnfurHvvvVeff/652WGWmIAS2OyCmRST/eEPf1DXrl3VpUsXde3aVQ0aNDA7pBJX\ns2ZNffrpp3m+sL/++mvFxMQoNTXVpMhKzv/+9z8lJyfrtttuU6VKlSRJq1evVpUqVTyWQsKa/P39\nlZqaqpo1a3rs//LLL9WtWzedO3fOpMhQGHfccYciIyP16quv5vv7hx9+WMnJyVqzZk0ZR1aycmdS\n5koy0sC6JGms7DGTQpJisrffflufffaZkpKSdPDgQdWpU0ddunRxJy3XXXed2SEaVr58ee3atUuN\nGjXy2L9v3z61adNGly5dMimykpWVlaUjR46oQYMGCgiw099VfFebNm3k5+enL7/8Us2aNfP49+Z0\nOnXkyBH16NFD77zzjolR4vdUq1ZNGzduLLBy+dVXX6lLly764YcfyjiykuWLSQp/kpqsf//+6t+/\nvyTp+++/18aNG/XRRx/pkUcekcvlktPpNDlC41q0aKHly5fneUfPsmXL1LRpU5OiKjkZGRkaM2aM\nFi1aJEk6cOCA6tevrzFjxqhOnTqaNGmSyRGiIL1795Yk7dq1S927d3dXwaSr7zaJiopiCbkN/PqJ\ns78WGhqqy5cvl2FEpctoy8ZOX/x2itVrZWRkaNOmTUpKStKGDRu0c+dONW/e3D3bYHdTp07V3Xff\nrUOHDumWW26RJCUmJmrp0qV5nmdgR5MnT9aXX36ppKQk9ejRw70/JiZG06dPJ0mxsLi4OElSVFSU\n7r///jyDs7CH6667Tp9++mmB80OJiYleUZXOZXR1z5WSCqQMkKSYrGPHjtq5c6eaNGmirl27atKk\nSbr55ptVtWpVs0MrMT179tTKlSv13HPPacWKFSpfvrxatmyp9evXq0uXLmaHZ9jKlSu1fPly3Xjj\njR4vT2zWrJkOHTpkYmQorFtuuUWnT59W3bp1JUnbtm3TkiVL1LRpU40YMcLk6PB7hgwZoscff1zh\n4eG64447PH63evVqPfHEE3ryySdNiq7kUUlBmdm3b58qVqyoxo0bq3HjxmrSpIlXJSi57rzzTt15\n551mh1EqTp8+rbCwsDz7L1686JG0wLoeeOABjRgxQgMGDFBKSopiYmLUvHlzLV68WCkpKXlalbCW\ncePGacuWLbrrrrvUqFEjNWnSRDk5Odq7d6++/fZb9e7dW+PHjzc7TBQDS5BNdvbsWX366ae68cYb\ntXbtWnXq1El16tTRAw88oPnz55sdHgqhXbt2Wr16tfvn3MTk9ddfV3R0tFlhoQh2796t9u3bS5Le\neecdtWjRQlu2bNHixYu1cOFCc4PD7/L399e7776rpUuXqlGjRtq3b5/279+vxo0ba/HixXrvvffk\n7+89X3e+9O4eVvdYSE5OjrZv366XX35Zixcv9prBWX9//9+sKNj9Hjdt2qQ//vGP6t+/vxYuXKiH\nH35Ye/bs0ZYtW7Rx40aPF53BmipVqqTdu3crKipKvXr1UqdOnTRx4kQdO3ZMjRo18poVaLC33NU9\nyyRVMPA5GZLulz1W93hPamlTO3bs0KxZs9SrVy9Vr15d0dHR+uqrrzRmzBi9//77ZodXIj744AO9\n//777m358uWaNGmSatWqpddee83s8Ay76aabtGvXLmVnZ6tFixZat26dwsLCtHXrVhIUm2jWrJnm\nzZun//znP/rkk0/cA9AnT55U9erVTY4Ov+edd95RVlaW++fjx4/L5XK5f87IyNDzzz9vRmgwiEqK\nyQICAtSmTRv3s1FuvvlmhYaGmh1WmViyZImWL1+uf//732aHAh+XlJSkP/3pT0pPT9egQYO0YMEC\nSdKTTz6pffv2ec1fGLyVw+HQ999/754NCwkJ0a5du1S/fn1JUmpqqmrXrm37qm1uJWWFjFdS7pU9\nKikMzprs3Llzlv8/SWm58cYbvWblhNPp1MqVK7V3715JV/9m3qtXLzkcDpMjQ2F07dpVZ86cUXp6\nusfg+ogRI1ShgpGvA5SFX/9d29v/7m10CbKdvvjtFKtXyk1Qtm/f7v6Ca9q0qa6//nozwyp1ly5d\n0ty5c1WnTh2zQzHs4MGDuvPOO3X8+HH3U3Xj4+MVGRmp1atXe+WrDryRw+FQdna2Nm3aJElq1KiR\noqKizA0K8HEkKSY7deqU+vbtq40bN6pKlSqSpB9//FHdunXTsmXL8rxLxI6qVq3qMTibk5Oj8+fP\nq3z58lq8eLGJkZWMsWPHqn79+u43IUtXV231799fY8eO9Vj5A2u6ePGixowZo7feess9y+BwODRw\n4ED9/e9/p5oCS+E5KSgzY8aM0YULF/TNN9+oSZMmkqQ9e/Zo0KBBGjt2rJYuXWpyhMa99NJLHkmK\nv7+/atasqQ4dOnjFM2E2btyozz//3J2gSFL16tU1c+ZMXi5oE7Gxsdq4caM+/PBD97+zTZs2aezY\nsXrsscf0z3/+0+QI8XvWrl3rnudzuVxKTEzU7t27JV39i583MbqMmCXIKLTQ0FCtX79eN9xwg8f+\nbdu26fbbb/ea/7guX76sr776SqdOnfKYupekXr16mRRVyahWrZo++ugjdezY0WP/5s2b1bNnT96g\nawM1atTQihUr8ryKYsOGDbrvvvt0+vRpcwJDoRTmGSh+fn5eMzibKKmigc+5KOlWMTiLQnC5XCpX\nLm9eW65cuTxf5naVkJCggQMH6uzZs3kG2rzhD4677rpLI0aM0BtvvOF+INgXX3yhkSNH2j4B8xUZ\nGRkKDw/Psz8sLEwZGRkmRISi8JY/K5EXz0kx2S233KJx48bp5MmT7n0nTpzQhAkTdOutt5oYWckZ\nM2aM+vTpo5MnT8rlcnlsdk9QJGnu3Llq0KCBoqOjFRwcrODgYHXs2FHXXnutZs+ebXZ4KITo6GjF\nxcV5vCn30qVLmjFjBk8NtomMjAx9/fXX+f7um2++0YULF8o4otKTu7qnuJudqhO0e0yWnJysXr16\n6ZtvvlFkZKQk6dixY2rRooVWrVrlfuGZnYWEhGjnzp1ev8rl4MGD7hVaTZo00bXXXmtyRCisr7/+\nWj169FBmZqZatWolSfryyy8VFBSkdevWqVmzZiZHiN/z448/qnbt2kpKSnJXNKWrM36tW7fWsWPH\nFBERYWKExuW2ezZLqmTgcy5I6iR7tHtIUiwgJydHiYmJHl9wMTExJkdVch566CF16tRJQ4cONTuU\nEhMbG1voY2fNmlWKkaCkZGRkaPHixdq3b5+kq/8dPvjggypfvrzJkaGw7rvvPoWFhenll19275s8\nebJ27dqljz/+2MTISgZJCkyRmJioxMTEfIdKc598aWcZGRnq06ePatasqRYtWuSZwRk7dqxJkRVf\nt27dPH7esWOHsrOz3c9JOXDggBwOh9q2batPP/3UjBBL1K+f6Jnr7NmzCgsLs33bLj4+XuHh4Xro\noYc89i9YsECnT5/WxIkTTYoMRbF69WoNHjxY33//vQICApSTk6NrrrlGL774ou677z6zwzMsN0nZ\nJuNJSnvZI0mxU2vKK82YMUNPP/202rVrp1q1av3mi/jsaunSpVq3bp2Cg4OVlJTkcY9+fn62TFI2\nbNjg/udZs2apcuXKWrRokXtJ9Q8//KAhQ4aoc+fOZoVYogr6u0xmZqYCAwPLOJqS9+qrr2rJkiV5\n9jdr1kz333+/7ZOUo0eP6uTJk2rfvr0CArz3j/0ePXooICBAq1ev1v/93/8pKSlJFy5cUO/evc0O\nrUT50nNSqKSYrFatWnr++ec1YMAAs0MpNRERERo7dqwmTZrkVa9Lz1WnTp185xZ2796t22+/3WMo\n2m7mzp0rSZowYYKeeeYZVar089/fnE6nPvvsMx09elQ7d+40K8QSERwcrL1796pevXoe+w8fPqym\nTZt6DNTazdKlSzVw4EA5nU61bNlSCQkJtp/N+C2PP/64jhw5ovfee08PPfSQgoKCvOY5N7mVlB0y\nXkm5XlRSUAhZWVl5nq/hbbKystS3b1+vTFCkq39w5PccjdOnT+v8+fMmRFRyXnrpJUlXKynz5s3z\neBdRYGCgoqKiNG/ePLPCKzGRkZHavHlzniRl8+bNql27tklRlYzp06dr2rRpGj16tGJjY9WtWzd9\n+OGHXjvYPWjQILVv314nTpzQe++9p7Vr15odUonzpXf3eOe3ho0MGzYs3zKzNxk0aJCWL19udhil\n5k9/+pOGDBmi999/X8ePH9fx48f13nvvaejQobr77rvNDs+QI0eO6MiRI+rSpYu++uor989HjhzR\n/v37tXbtWnXo0MHsMA0bPny4xo8frzfffFPfffedvvvuOy1YsEATJkzQ8OHDzQ7PkOPHj2vAgAGq\nWrWq3nzzTXXs2FENGzaUw+HQjh071KRJE696EWaLFi3UtGlTPfjgg6pVq5ZuvPFGs0MqcUaWHxt9\nWm1Zs1NC5TV+uTLE5XLptdde0/r169WyZcs8Q6XesDLE6XTq+eef19q1a73yHufNm6fHH39cDzzw\ngK5cuSJJCggI0NChQ/XCCy+YHF3xxcbG6plnnlHFihXVunVrPf300wUea/d/h3/+85919uxZPfLI\nI8rKypJ0tQU0ceJETZ482eTojKlXr54OHTrkflniG2+8oZEjR+r7779XgwYNFB8fr7S0NHODLGED\nBw7UhAkT9Oyzz5odCgxiJsUEv14ZUhA/Pz+vWBnyW/frLfcoXX1J3aFDhyRJDRo0UMWKRh5cbb5u\n3brpgw8+UJUqVXzm3+GFCxe0d+9elS9fXtddd52CgoLMDsmwmTNnavPmzfrwww/NDqXMnDt3Tn//\n+9/18MMPe9X8Te5MyreSKhv4nPOSrpM9ZlJIUgAAsIHcJOWIQwoxsBA0PUeq57RHkkK7BwAAGwkI\nkAIMJCkBOZJs8mgjBmcBAIAlkaRYSGZmpqZPn67MzEyzQykV3n5/EvfoDbz9/iTu0e7KOYxvdsFM\nioXk9hvt0CcsDm+/P4l79Abefn8S92hXufd0JsT4TEqNdHvMpFBJAQAAlsTgLAAANlLOIZUzUGIo\n5/r9Y6yCJKUALpdLJ0+eVOXKlcvspX/p6eke/+ttvP3+JO7RG3j7/UncY2nIycnR+fPnVbt27dJ/\nBYhDxvogNnqPLTMpBTh+/LgiIyPNDgMAYCPJycmqW7duqXy2e86mhhRiIElJd0mhZ+wxk0IlpQCV\nK+c+z2+CJPs/dRKAtf1VM80OoVRN1F/NDqGUXZYU94vvjlIUIGOVFNo99vdziydIJCkASluw2QGU\nOu+/Q0llMx7gQ0kKq3sAAIAlUUkBAMBOfKiSQpICAICd+OvqCh8fQJICAICdBMhYkmKjJcjMpAAA\nAEuikgIAgJ34UCWFJAUAADtxyGdmUmj3AAAAS6KSAgCAndDuAQAAluSQz3x70+4BAACW5CO5GAAA\nXsLo4GxOSQVS+khSAACwkwD5zLc37R4AAGBJPpKLAQDgJXyokuIjtwkAgJcgSQEAAJZk9C3IrpIK\npPQxkwIAACyJSgoAAHZitN3DEmQAAFAqfChJsVW7Z/Dgwerdu3ehjj169Kj8/Py0a9euUo4KAACU\nBltVUubMmaOcHBulgAAAlDSjT5y10eCsrZKU0NBQs0MAAMBctHus6ZftnoSEBN10002qUqWKqlev\nrrvuukuHDh0q8Fyn06mHHnpIjRs31rFjx8oqZAAAUEy2SlJ+6eLFi4qNjdX//vc/JSYmyt/fX3/6\n05/kcuWtY2VmZqpPnz7atWuX/vOf/+gPf/hDvsekp6d7bAAAWI5DP1dTirMVs1X0yiuvKCoqSsHB\nwerQoYO2bdv2m8fPnj1bjRo1Uvny5RUZGakJEybo8uXLRbqmrdo9v3TPPfd4/LxgwQLVrFlTe/bs\nUfPmzd37L1y4oDvvvFOZmZnasGFDgS2j+Ph4zZgxo1RjBgDAMKMzKcU4d/ny5YqNjdW8efPUoUMH\nzZ49W927d9f+/fsVFhaW5/glS5Zo0qRJWrBggTp27KgDBw5o8ODB8vPz06xZswp9XdtWUr799lv1\n69dP9evXV0hIiKKioiQpTyunX79+unjxotatW/ebMy2TJ09WWlqae0tOTi7N8AEAsI1Zs2Zp+PDh\nGjJkiJo2bap58+apQoUKWrBgQb7Hb9myRZ06ddIDDzygqKgo3X777erXr9/vVl9+zbZJSs+ePXXu\n3DnNnz9fX3zxhb744gtJUlZWlsdxd9xxh7766itt3br1Nz8vKChIISEhHhsAAJZjpNXzi6HbX484\nZGZm5nu5rKwsbd++XTExMe59/v7+iomJKfC7tWPHjtq+fbs7KTl8+LDWrFmjO+64o8i3ajtnz57V\n/v37NX/+fHXu3FmStGnTpnyPHTVqlJo3b65evXpp9erV6tKlS1mGCgBAyTK6uuen0c3IyEiP3XFx\ncZo+fXqew8+cOSOn06nw8HCP/eHh4dq3b1++l3jggQd05swZ3XTTTcrJyVF2drZGjhypJ598skih\n2jJJqVq1qqpXr67XXntNtWrV0rFjxzRp0qQCjx8zZoycTqfuuusuffzxx7rpppvKMFoAAEpQCSUp\nycnJHl2DoKAgQ2H9UlJSkp577jn94x//UIcOHXTw4EGNGzdOzzzzjKZOnVroz7FlkuLv769ly5Zp\n7Nixat68uRo1aqS5c+eqa9euBZ4zfvx4uVwu3XHHHUpISFDHjh3LLmAAACymsKMNNWrUkMPhUGpq\nqsf+1NRURURE5HvO1KlTNWDAAA0bNkyS1KJFC128eFEjRozQU089JX//wk2b2CpJyczMVKVKlSRJ\nMTEx2rNnj8fvf/k02qioqDxPp42NjVVsbGzpBwoAQGnxl7HVPUWcRg0MDFTbtm2VmJjoflaZy+VS\nYmKiRo8ene85GRkZeRIRh+Nq0EV5crwtkpTs7GwdOHBAW7du1cMPP2x2OAAAmMdou8dZ9FNiY2M1\naNAgtWvXTu3bt9fs2bN18eJFDRkyRJI0cOBA1alTR/Hx8ZKuLm6ZNWuW2rRp4273TJ06VT179nQn\nK4VhiyRl9+7d6tixo7p166aRI0eaHQ4AAD6lb9++On36tKZNm6aUlBS1bt1aCQkJ7mHaY8eOeVRO\npkyZIj8/P02ZMkUnTpxQzZo11bNnT/3lL38p0nX9cnhjX77S09N/eq7KJEklN0wEAPmZI+9+mOQ4\nzTE7hFJ2WdJEpaWlldojLHK/l9LGSyEGvpbSM6XQ2SrVWEuKLSopAADgJyY8cdYstn2YGwAA8G5U\nUgAAsBMTBmfNQpICAICd5L4FubiySyqQ0ke7BwAAWBKVFAAA7MRou8dG3/w2ChUAAPjS6h6SFAAA\n7MSHKinMpAAAAEuyUT4FAAB8qZJio1ABAEBZvwXZTDYKFQAA+BIqKQAA2AntHgAAYEk+lKTQ7gEA\nAJZko3wKAADwMDcAAGBNtHsAAADMZaN8CkD+YswOoPR1vcnsCErd2EdmmB1CqRp3n9kReBGHjH17\n0+4BAAClwofaPTYKFQAA+NLgLDMpAADAkqikAABgJ7R7AACAJflQkkK7BwAAWJKN8ikAACB/GRt+\ntVF5giQFAAA7od0DAABgLhvlUwAAwJcqKTYKFQAA8DA3AAAAk1FJAQDATmj3AAAAS+ItyAAAwJJ8\nqJLCTAoAALAkG+VTAADAl1b3kKQAAGAntHsAAADMZaN8CgAAsLoHAABYkw/NpNDuAQAAlkQlBQAA\nO/GhwVkbhQoAAHwpSfGKdk/Xrl01fvx4s8MAAAAlyEb5FAAAoJJiI4MHD9bGjRs1Z84c+fn5yc/P\nT0ePHtXGjRvVvn17BQUFqVatWpo0aZKys7PNDhcAAENy/KUch4HNRt/8Nsqn8jdnzhwdOHBAzZs3\n19NPPy1JcjqduuOOOzR48GC99dZb2rdvn4YPH67g4GBNnz4938/JzMxUZmam++f09PSyCB8AgCJx\nBlzdjJxvFzYKNX+hoaEKDAxUhQoVFBERIUl66qmnFBkZqZdffll+fn5q3LixTp48qYkTJ2ratGny\n98+bRsbHx2vGjBllHT4AACiAjYo+hbd3715FR0fLz8/Pva9Tp066cOGCjh8/nu85kydPVlpamntL\nTk4uq3ABACi03EqKkc0ubBRq6QoKClJQUJDZYQAA8JuyHX7Kdvj9/oEFnp8jKafkAipFXlFJCQwM\nlNPpdP/cpEkTbd26VTk5P/9L2Lx5sypXrqy6deuaESIAACgir0hSoqKi9MUXX+jo0aM6c+aMHnnk\nESUnJ2vMmDHat2+f/v3vfysuLk6xsbH5zqMAAGAXzoAAw5tdeMU39uOPPy6Hw6GmTZuqZs2aunLl\nitasWaNt27apVatWGjlypIYOHaopU6aYHSoAAIY4HQ7Dm13YJ536DQ0bNtTWrVs99kVFRWnbtm0m\nRQQAAIzyiiQFAABf4ZJDThV/cNZlk6FZiSQFAABbyZZD2QaSlGwbJSleMZMCAAC8D5UUAABsxCmH\nnAZqDE65SjCa0kWSAgCAjRhPUorfKiprJCkAANiILyUpzKQAAABLopICAICN+FIlhSQFAAAbccqh\nbB9JUmj3AACA3/XKK68oKipKwcHB6tChw+8+1f3HH3/Uo48+qlq1aikoKEgNGzbUmjVrinRNKikA\nANiIUwFlvgR5+fLlio2N1bx589ShQwfNnj1b3bt31/79+xUWFpbn+KysLN12220KCwvTihUrVKdO\nHX333XeqUqVKka5LkgIAgI045S+niv+SQGcxzpk1a5aGDx+uIUOGSJLmzZun1atXa8GCBZo0aVKe\n4xcsWKBz585py5YtKleunKSr79QrKto9AAD4oPT0dI8tMzMz3+OysrK0fft2xcTEuPf5+/srJiYm\nz8t9c61atUrR0dF69NFHFR4erubNm+u5556T01m0FIkkBQAAG7m6usfYJkmRkZEKDQ11b/Hx8fle\n78yZM3I6nQoPD/fYHx4erpSUlHzPOXz4sFasWCGn06k1a9Zo6tSp+tvf/qZnn322SPdKuwcAABu5\n+oLB4rd7sn/63+TkZIWEhLj3BwUFGYzsZy6XS2FhYXrttdfkcDjUtm1bnThxQi+88ILi4uIK/Tkk\nKQAA+KCQkBCPJKUgNWrUkMNTVkwkAAAYsUlEQVThUGpqqsf+1NRURURE5HtOrVq1VK5cOTkcPydT\nTZo0UUpKirKyshQYGFioGGn3AABgIy4F/LTCp3ibq4j1icDAQLVt21aJiYk/x+ByKTExUdHR0fme\n06lTJx08eFAu188riQ4cOKBatWoVOkGRSFIAALCVkppJKYrY2FjNnz9fixYt0t69ezVq1ChdvHjR\nvdpn4MCBmjx5svv4UaNG6dy5cxo3bpwOHDig1atX67nnntOjjz5apOvS7gEAwEaKm2j8fH7R9e3b\nV6dPn9a0adOUkpKi1q1bKyEhwT1Me+zYMfn7/1z3iIyM1Nq1azVhwgS1bNlSderU0bhx4zRx4sQi\nXZckBQAA/K7Ro0dr9OjR+f4uKSkpz77o6Gh9/vnnhq5JkgLY3nqzAyh9Sd5/j9OTzI6gtJ0zO4BS\nlv8zRkqD8Ye55ZRgNKWLJAUAABsxvgTZPkkKg7MAAMCSqKQAAGAjuUuJi3++fZCkAABgIy6Dq3tc\ntHsAAACMoZICAICNGH9Oin0qKSQpAADYSLb8Da7ucf3+QRZBuwcAAFgSlRQAAGzE+Ooe2j0AAKAU\nGJ9JsU+7hyQFAAAb8aUkhZkUAABgSVRSAACwEafBd/fYqZJCkgIAgI340uAs7R4AAGBJVFIAALAR\np/wNDs7a5xWDJCkAANiI8dU9xT+3rNHuAQAAlkQlBQAAG/GlSgpJCgAANmJ8CbJ9khTaPQAAwJKo\npAAAYCPGn5PCw9wAAEApYCYFAABYkvHnpNhn0sOykQ4ePFi9e/c2OwwAAGASy1ZS5syZo5wc4+8X\nOHr0qOrVq6edO3eqdevWJRAZAADmyTa4usfIuWXNsklKaGio2SEAAGA5xgdn7fNYfFu0e1wul+Lj\n41WvXj2VL19erVq10ooVK9zH/vDDD3rwwQdVs2ZNlS9fXtddd53efPNNSVK9evUkSW3atJGfn5+6\ndu1a5vcCAACKzrKVlF+Kj4/X22+/rXnz5um6667TZ599pv79+6tmzZrq0qWLpk6dqj179ujjjz9W\njRo1dPDgQV26dEmStG3bNrVv317r169Xs2bNFBgYmO81MjMzlZmZ6f45PT29TO4NAICicBlc3eOi\n3VNyMjMz9dxzz2n9+vWKjo6WJNWvX1+bNm3Sq6++qi5duujYsWNq06aN2rVrJ0mKiopyn1+zZk1J\nUvXq1RUREVHgdeLj4zVjxozSuxEAAEqALy1Btmy7J9fBgweVkZGh2267TZUqVXJvb731lg4dOiRJ\nGjVqlJYtW6bWrVvriSee0JYtW4p8ncmTJystLc29JScnl/StAACAIrB8JeXChQuSpNWrV6tOnToe\nvwsKCpIk/fGPf9R3332nNWvW6JNPPtGtt96qRx99VC+++GKhrxMUFOT+PAAArMqXnpNi+SSladOm\nCgoK0rFjx9SlS5cCj6tZs6YGDRqkQYMGqXPnzvrzn/+sF1980T2D4nTaZ5oZAICCZMshB0uQraFy\n5cp6/PHHNWHCBLlcLt10001KS0vT5s2bFRISokGDBmnatGlq27atmjVrpszMTH300Udq0qSJJCks\nLEzly5dXQkKC6tatq+DgYJY3AwBgA7ao+TzzzDOaOnWq4uPj1aRJE/Xo0UOrV692Ly8ODAzU5MmT\n1bJlS918881yOBxatmyZJCkgIEBz587Vq6++qtq1a+v//u//zLwVAAAMyX1OipHNLiwbaWZmpipV\nqiRJ8vPz07hx4zRu3Lh8j50yZYqmTJlS4GcNGzZMw4YNK5U4AQAoS760BNlylZTs7Gzt2bNHW7du\nVbNmzcwOBwAAS8ldgmxkswvLJSm7d+9Wu3bt1KxZM40cOdLscAAAgEks1+5p3bq1MjIyzA4DAABL\nypZD/qzuAQAAVnO1ZWPkBYP2SVIs1+4BAACQqKQAAGArvvTuHpIUAABsxJeSFNo9AADAkqikAABg\nI770MDeSFAAAbCRbDvn5yBJk2j0AAMCSqKQAAGAjTjnk7yPPSSFJAQDARpwGnzhLkgIAAEqFLyUp\nzKQAAABLopICAICN+NLqHpIUAABsxKUAQy8YdNnoq592DwAAsCT7pFMAAEBOg+0eOw3OkqQAAGAj\nTvkbTFLs00SxT6QAAMCnUEkBAMBGrq7OYXUPAACwGKcC5Gfosfj2+eqn3QMAACzJPukUAACQSw5D\nK3RctHsAAEBpcBqcSbHTEmTaPQAA2Ijzp0qKka04XnnlFUVFRSk4OFgdOnTQtm3bCnXesmXL5Ofn\np969exf5miQpAADgNy1fvlyxsbGKi4vTjh071KpVK3Xv3l2nTp36zfOOHj2qxx9/XJ07dy7WdUlS\nAACwkWz5K1sOA1vRv/pnzZql4cOHa8iQIWratKnmzZunChUqaMGCBQWe43Q69eCDD2rGjBmqX79+\nse6VJAUAABtx/vSCQSObJKWnp3tsmZmZ+V4vKytL27dvV0xMjHufv7+/YmJitHXr1gLjfPrppxUW\nFqahQ4cW+15JUgAA8EGRkZEKDQ11b/Hx8fked+bMGTmdToWHh3vsDw8PV0pKSr7nbNq0SW+88Ybm\nz59vKEZW9wAAYCMltbonOTlZISEh7v1BQUFGQ5MknT9/XgMGDND8+fNVo0YNQ59FkgIAgI24DCYp\nuc9JCQkJ8UhSClKjRg05HA6lpqZ67E9NTVVERESe4w8dOqSjR4+qZ8+eP1/T5ZIkBQQEaP/+/WrQ\noEGhYqXdAwAAChQYGKi2bdsqMTHRvc/lcikxMVHR0dF5jm/cuLG+/vpr7dq1y7316tVL3bp1065d\nuxQZGVnoa1NJAQDARrLlkH8ZP3E2NjZWgwYNUrt27dS+fXvNnj1bFy9e1JAhQyRJAwcOVJ06dRQf\nH6/g4GA1b97c4/wqVapIUp79v4ckBQAAG3HKoRwDX9/FSVL69u2r06dPa9q0aUpJSVHr1q2VkJDg\nHqY9duyY/P1LvjlDkgIAAH7X6NGjNXr06Hx/l5SU9JvnLly4sFjXJEkBAMBGrlZSeMEgAACwGJIU\nAABgSU6XQzkuA0mKgXPLGkuQAQCAJVFJAQDARpzZDrmyi18NyTFwblkjSQEAwEac2QHyyy7+13eO\ngXPLGu0eAABgSfZJpwAAgJzZ/vIz1O6xT33CPpEWw8yZM9WsWTNVqFBBDRs21JIlS8wOCQAAQ5zZ\nDsObXXh1kvKf//xHL730knbv3q3+/ftr4MCBOnz4sNlhAQCAQvDqds/q1avd/zx69GjFxcXp5MmT\nql+/volRAQBQfNnZDvldYXWP18jJydFjjz2m5s2bq3379vkek5mZqczMTPfP6enpZRUeAACFluMM\nUI7TwNe3kXPLmFe3e3INGzZMW7ZsUUJCggIDA/M9Jj4+XqGhoe4tMjKyjKMEAAC/5PVJyn//+18t\nWLBAq1atUp06dQo8bvLkyUpLS3NvycnJZRglAACFlO0wvtmEfWo+xXTy5ElJUqNGjX7zuKCgIAUF\nBZVFSAAAFJ/RRIMkxTq6dOmi//73v2aHAQBAyXD6Sdl+xs63Ca9v92zYsEH9+/c3OwwAAFBEXl9J\nSUtL0/79+80OAwCAkpH902bkfJvw+krK4MGDlZOTY3YYAACUjOwS2GzC65MUAABgT17f7gEAwKv4\nULuHJAUAADvJlnTF4Pk2QbsHAABYEpUUAADsxPnTZuR8myBJAQDATphJAQAAluRDSQozKQAAwJKo\npAAAYCc+VEkhSQEAwE6cMpZo2GhwlnYPAACwJCopAADYCe0eAABgST6UpNDuAQAAlkQlBQAAO7ki\nY+/uMXJuGSNJAQDATnzosfi0ewAAgCVRSQEAwE586DkpJCkAANiJD63uIUkBAMBOfChJYSYFAABY\nEpUUALCAGYozO4RSFacZZodQqjIlzSyri/lQJYUkBQAAO/GhwVnaPQAAwJKopAAAYCe0ewAAgCVd\nkeQweL5N0O4BAACWRCUFAAA78aF395CkAABgJz40k0K7BwAAWBKVFAAA7MSHnpNCkgIAgJ1ky9jq\nHhu1e0hSAACwkysyNqzBEmQAAABjqKQAAGAnLEEGAACW5EODs7R7AACAJVFJAQDATrJlrMTA6h4A\nAFAqrkjyM3i+TdDuAQAAlkQlBQAAO2F1DwAAsCQfmkmh3QMAACyJJAUAADvJfU5KcbditnteeeUV\nRUVFKTg4WB06dNC2bdsKPHb+/Pnq3LmzqlatqqpVqyomJuY3jy8ISQoAAHZypQS2Ilq+fLliY2MV\nFxenHTt2qFWrVurevbtOnTqV7/FJSUnq16+fNmzYoK1btyoyMlK33367Tpw4UaTrkqQAAGAnzhLY\nimjWrFkaPny4hgwZoqZNm2revHmqUKGCFixYkO/xixcv1iOPPKLWrVurcePGev311+VyuZSYmFik\n65ZqkuLn55fvtmzZMvcxTqdTL730klq0aKHg4GBVrVpVf/zjH7V582aPz3I6nZo5c6YaN26s8uXL\nq1q1aurQoYNef/310rwFAAB8WlZWlrZv366YmBj3Pn9/f8XExGjr1q2F+oyMjAxduXJF1apVK9K1\nS3x1zw8//KBy5cqpUqVKkqQ333xTPXr08DimSpUqkqScnBzdf//9Wr9+vV544QXdeuutSk9P1yuv\nvKKuXbvq3XffVe/evSVJM2bM0KuvvqqXX35Z7dq1U3p6uv73v//phx9+cH/uyZMnFRYWpoAAFi0B\nALxUtow9zO2n1T3p6ekeu4OCghQUFJTn8DNnzsjpdCo8PNxjf3h4uPbt21eoS06cOFG1a9f2SHQK\no0S+zbOzs7V27VotXLhQH374ob744gu1atVK0tWEJCIiIt/z3nnnHa1YsUKrVq1Sz5493ftfe+01\nnT17VsOGDdNtt92mihUratWqVXrkkUfUp08f93G518g1f/58/fOf/1T//v01aNAgtWjRoiRuDwAA\n6yihJCUyMtJjd1xcnKZPn27gg/M3c+ZMLVu2TElJSQoODi7SuYbaPV9//bUee+wx1a1bVwMHDlTN\nmjW1YcOGPMlDQZYsWaKGDRt6JCi5HnvsMZ09e1affPKJJCkiIkKffvqpTp8+XeDnTZw4UXPmzNHe\nvXt1/fXX6/rrr9fcuXN/85xcmZmZSk9P99gAAPBWycnJSktLc2+TJ0/O97gaNWrI4XAoNTXVY39q\namqBRYhcL774ombOnKl169apZcuWRY6xyEnK2bNnNWfOHF1//fVq166dDh8+rH/84x/6/vvv9Y9/\n/EPR0dEex/fr10+VKlXy2I4dOyZJOnDggJo0aZLvdXL3HzhwQNLVoZ3Tp08rIiJCLVu21MiRI/Xx\nxx97nBMcHKy+fftq9erVOnHihAYOHKiFCxeqTp066t27tz744ANlZ+f/FJv4+HiFhoa6t19nmAAA\nWEK2jK3s+elrMCQkxGPLr9UjSYGBgWrbtq3H0GvuEOyvv/N/6fnnn9czzzyjhIQEtWvXrli3WuQk\n5e9//7vGjx+vSpUq6eDBg/rggw909913KzAwMN/jX3rpJe3atctjq127tvv3OTk5hbpu06ZNtXv3\nbn3++ed66KGHdOrUKfXs2VPDhg3L9/iwsDCNHz9eO3bs0L///W9t3bpVd999t3bv3p3v8ZMnT/bI\nKJOTkwsVFwAAZcqE1T2xsbGaP3++Fi1apL1792rUqFG6ePGihgwZIkkaOHCgRyXmr3/9q6ZOnaoF\nCxYoKipKKSkpSklJ0YULF4p03SLPpIwYMUIBAQF666231KxZM91zzz0aMGCAunbtKn//vDlPRESE\nrr322nw/q2HDhtq7d2++v8vd37BhQ/c+f39/3XDDDbrhhhs0fvx4vf322xowYICeeuop1atXz+P8\n8+fPa8WKFfrXv/6lzz77TF26dNGgQYPUtGnTfK9X0MAQAAC+rm/fvjp9+rSmTZumlJQUtW7dWgkJ\nCe5h2mPHjnnkAP/85z+VlZWle++91+Nzijr3UuQkpXbt2poyZYqmTJmiLVu2aNGiRbr77rtVuXJl\nPfjggxowYICaNWtWqM+6//779cADD+jDDz/MM5fyt7/9TdWrV9dtt91W4Pm5CcfFixclXV2mvG7d\nOv3rX//SypUrFRkZ6W75/OEPfyjqrQIAYD1G371TzPNHjx6t0aNH5/u7pKQkj5+PHj1avIv8iqHV\nPR07dlTHjh01Z84crVy5UgsXLtSLL76onTt3ulfW/Pjjj0pJSfE4r3LlyqpYsaLuv/9+vfvuuxo0\naFCeJcirVq3Su+++q4oVK0qS7r33XnXq1EkdO3ZURESEjhw5osmTJ6thw4Zq3LixJOm5557T3/72\nN/Xt21fr169Xx44djdweAADWY1KSYga/nMIOhRTSyZMnValSJYWEhMjPL/81UvHx8Zo0aZKkq8uX\nZ8+erYULF+rbb79VcHCwoqOjNXXqVHXq1Ml9zvz587V06VLt3r1baWlpioiI0C233KLp06frmmuu\nkXQ1c4uIiCjyEqf8pKenKzQ0VNIkSbSBAMCIOM0wO4RSlSlppqS0tDSFhISUyjXc30s3pEkBBq6R\nnS79N7RUYy0pJZ6keAuSFAAoOSQpxrm/l9qkSQ4D13CmSzvtkaTwaFYAAOykmG8xLrHzyxBJCgAA\ndpItyUgPxEZJCm9BBgAAlkQlBQAAO/GhSgpJCgAAdpItyWXgfCPnljHaPQAAwJKopAAAYCdOGWv3\n2KiSQpICAICdZMtYH8RGSQrtHgAAYElUUgAAsBMfqqSQpAAAYCdX5DNJCu0eAABgSVRSAACwE5eM\nre6x0WuFSVIAALCTbEl+Bs4nSQEAAKXCh5IUZlIAAIAlUUkBAMBOrshnKikkKQAA2IlTPpOk0O4B\nAACWRCUFAAC7sVE1xAiSlALk5OT+PyDT1DgAwBt4+5+kuff383cHSgJJSgHOnz//0z+9ZGocAOAN\nZpodQBk5f/68QkNDzQ7Da5CkFKB27dpKTk5W5cqV5ednZEKp8NLT0xUZGank5GSFhISUyTXLkrff\nn8Q9egNvvz+JeywNOTk5On/+vGrXrl3q1/IlJCkF8Pf3V926dU25dkhIiNf+wSF5//1J3KM38Pb7\nk7jHkkYFpeSxugcAAFgSlRQAAGzlyk+bkfPtgSTFQoKCghQXF6egoCCzQykV3n5/EvfoDbz9/iTu\n0f6yf9qMnG8PfjmslwIAwPLS09N/mntJlmRkziZdUqTS0tIsP5PETAoAALAk2j0AANiK77R7SFIA\nALCVbBkbfrVPkkK7BwAAWBKVFAAAbIUlyAAAwJJ8ZyaFdg8AALAkKikAANiK7wzOkqQAAGArtHsA\nAABMRSUFAABbYXUPAACwJN9p95CkAABgK74zOMtMCgAAsCQqKQAA2ArtHgAAYEm+MzhLuwcAAFgS\nlRQAAGyFdg8AALAkVvcAAACYikoKAAC2QrsHAABYEqt7AAAATEUlBQAAW/GdSgpJCgAAtsJMCgAA\nsCSWIAMAAJiKSgoAALZCuwcAAFjSFRn7+rbP4CztHgAAYElUUgAAsBXaPQAAwJJY3QMAAOD2yiuv\nKCoqSsHBwerQoYO2bdv2m8e/++67aty4sYKDg9WiRQutWbOmyNckSQEAwFayS2ArmuXLlys2NlZx\ncXHasWOHWrVqpe7du+vUqVP5Hr9lyxb169dPQ4cO1c6dO9W7d2/17t1bu3fvLtJ1/XJycnKKHC0A\nAChT6enpCg0NlTRFUrCBT7os6VmlpaUpJCSkUGd06NBBN9xwg15++WVJksvlUmRkpMaMGaNJkybl\nOb5v3766ePGiPvroI/e+G2+8Ua1bt9a8efMKHSmVFAAAbCVTVxON4m6ZRbpaVlaWtm/frpiYGPc+\nf39/xcTEaOvWrfmes3XrVo/jJal79+4FHl8QBmcBALCBwMBASZUkvWD4syIiInT58mWPfUFBQQoK\nCspz7JkzZ+R0OhUeHu6xPzw8XPv27cv381NSUvI9PiUlpUhxkqQAAGADwcHBunTptLKysgx/1vPP\nP58niYiLi9P06dMNf3ZJIkkBAMAmgoODFRxsZB7lqqlTp+qJJ57w2JdfFUWSatSoIYfDodTUVI/9\nqampioiIyPeciIiIIh1fEGZSAADwMUFBQQoJCfHYCkpSAgMD1bZtWyUmJrr3uVwuJSYmKjo6Ot9z\noqOjPY6XpE8++aTA4wvimG612g4AALCUkJAQTZ06VZGRkQoKCtLUqVO1a9cuvfHGG6pUqZIGDhyo\nbdu2uYdl69SpoylTpqhixYqqVq2aXn75ZS1fvlxvvPGGwsLCCn1d2j0AAOA39e3bV6dPn9a0adOU\nkpKi1q1bKyEhwT3XcuzYMfn7/9yc6dixo5YsWaIpU6boySef1HXXXaeVK1eqefPmRbouz0kBAACW\nxEwKAACwJJIUAABgSSQpAADAkkhSAACAJZGkAAAASyJJAQAAlkSSAgAALIkkBQAAWBJJCgAAsCSS\nFAAAYEkkKQAAwJJIUgAAgCX9P61RNDOl1YLPAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fa5e5bb6ef0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"YpEnUGovjNAA","colab_type":"text"},"cell_type":"markdown","source":["## Wyrysowywanie strat treningowych\n","\n","Wykreślanie odbywa się za pomocą matplotlib, przy użyciu tablicy `plot_losses`, która została utworzona podczas treningu.\n"]},{"metadata":{"id":"E4uxpB9ljNAB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def show_plot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)\n","\n","show_plot(plot_losses)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TQFXl0RuYXSs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["MIN_COUNT = 3  # 5\n","xxx=[print(random.choice(pairs)) for i in range(10)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vQoeHfjfjNAC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["output_words, attentions = evaluate(\"it's time for lunch .\")\n","plt.matshow(attentions.numpy())\n","show_plot_visdom()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yt5xbOUMYXSy","colab_type":"raw"},"cell_type":"markdown","source":["['i failed after all .', 'nie udało mi się jednak .']\n","['i like you very much .', 'bardzo cię lubię .']\n","[\"i can't leave .\", 'nie mogę wyjść .']\n","['i feel very good .', 'czuję się bardzo dobrze .']\n","[\"we've been here an hour .\", 'jesteśmy tutaj godzinę .']\n","[\"i don't like it .\", 'nie lubię tego .']\n","['tom likes boston .', 'tom lubi boston .']\n","['that works .', 'to działa .']\n","['i will try it again .', 'spróbuję ponownie .']\n","['tom drank some beer .', 'tom wypił piwo .']"]},{"metadata":{"id":"Mb-wKK0yjNAE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention('i failed after all .', 'nie udało mi się jednak .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MjIOvXDajNAG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention('i like you very much .', 'bardzo cię lubię .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KygYF6nwjNAH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention(\"i can't leave .\", 'nie mogę wyjść .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2hL33p-mjNAK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention('i feel very good .', 'czuję się bardzo dobrze .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QE9BdY7RjNAL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention(\"we've been here an hour .\", 'jesteśmy tutaj godzinę .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8qyorxdcjNAM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["evaluate_and_show_attention(\"i don't like it .\", 'nie lubię tego .')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NsPR5AvxGR2Z","colab_type":"text"},"cell_type":"markdown","source":["# Zapis modelu"]},{"metadata":{"id":"SGKUbnuBGR2a","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# model: encoder, decoder, vocab: lang1, lang2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hoiNGMIhGR2b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder.state_dict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3SHpy70OGR2e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["decoder.state_dict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-sA4goeaGR2f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["ls -lah data/seq2seq/tmp"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XrhzilzDGR2h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from pathlib import Path\n","import pickle\n","dataset_path = Path('data/seq2seq')\n","tmp_path = dataset_path / 'tmp/'\n","!mkdir -p $tmp_path"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xAkaHdO6GR2i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["VOCAB, ENCODER, DECODER = ['vocab', 'encoder', 'decoder']\n","fn_trn1 = {VOCAB: 'eng-pol.vocab.1.p', \\\n","           ENCODER: 'batched.encoder.h500.l2.e10000.gpu.torch', \\\n","           DECODER: 'batched.decoder.h500.l2.e10000.gpu.torch'\n","          }\n","fn_dict = fn_trn1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cG532kFwGR2l","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","torch.save(encoder, tmp_path / fn_dict[ENCODER])\n","torch.save(decoder, tmp_path / fn_dict[DECODER])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yzhp7KgjGR2n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# save vocab\n","\n","vocab = {'input_lang': input_lang, 'output_lang': output_lang}\n","\n","pickle.dump(vocab, open(tmp_path / fn_dict[VOCAB], 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SLsYCGo2GR2o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["ls -lah $tmp_path"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8zBBVHQXjNAS","colab_type":"text"},"cell_type":"markdown","source":["# Ćwiczenia\n","\n","* Spróbuj użyć inny zestaw danych\n","    * Inna para języków\n","    * Człowiek &rarr; Maszyna (np. Komendy IOT)\n","    * Czat &rarr; Odpowiedź\n","    * Pytanie &rarr; Odpowiedź\n","* Zastąp zastosowane osadzenie przetrenowanymi wcześniej osadzeniami, takimi jak word2vec lub GloVe\n","* Wypróbuj więcej warstw, więcej ukrytych jednostek i więcej zdań. Porównaj czas trenowania i wyniki.\n","* Jeśli używasz pliku tłumaczenia, w którym pary mają dwie takie same frazy (`I am test \\t I am test`), możesz użyć tego jako autoencoder. Spróbuj tego:\n","    * Trenuj jako autoencoder\n","    * Zapisz tylko sieć kodera\n","    * Wytrenuj nowy dekoder do tłumaczenia, wykorzystując wcześniej wytrenowany koder\n"]}]}