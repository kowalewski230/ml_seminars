{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"char-rnn-generation-wcz2-benchmark.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1DztHxtFb_tfNmrLeOcav9myCNqeTlZ82","timestamp":1524483516973},{"file_id":"1sv_cPvPEWEOrG9wS3fPjAOj-Wvs6kc0P","timestamp":1524467882593}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"dvAIZr6jjuI5","colab_type":"text"},"cell_type":"markdown","source":["# char-rnn-generation benchmark"]},{"metadata":{"id":"xKp0KSueWk0U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":153},"outputId":"d14a2725-9995-4541-ee74-f63166bb701d","executionInfo":{"status":"ok","timestamp":1524491157738,"user_tz":-120,"elapsed":1403,"user":{"displayName":"Wojtek Czarnowski","photoUrl":"//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg","userId":"115130698336476923651"}}},"cell_type":"code","source":["import os\n","import psutil\n","\n","def print_memsize():\n","  process = psutil.Process(os.getpid())\n","  print(f'{process.memory_info().rss / 1024**3:.5} GB')\n","  \n","\n","import torch\n","\n","USE_GPU = torch.cuda.is_available(); \n","# USE_GPU = False; \n","\n","print(f'USE_GPU={USE_GPU}')\n","\n","def to_gpu(x, *args, **kwargs):\n","    return x.cuda(*args, **kwargs) if USE_GPU else x\n","  \n","  \n","# fn = 'data/tiny-shakespeare.txt'\n","fn = 'data/mickiewicz.txt'\n","\n","# import unidecode\n","import string\n","import random\n","import re\n","\n","# file = unidecode.unidecode(open(fn).read())\n","file = open(fn).read()\n","file_len = len(file)\n","print('file_len =', file_len)\n","\n","# ascii only\n","all_characters = string.printable\n","n_characters = len(all_characters)\n","\n","\n","# all chars found in file\n","all_characters = list(set(file));\n","n_characters = len(all_characters)\n","\n","\n","chunk_len = 200\n","\n","def random_chunk():\n","    start_index = random.randint(0, file_len - chunk_len)\n","    end_index = start_index + chunk_len + 1\n","    return file[start_index:end_index]\n","\n","print(random_chunk())\n","print_memsize()\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        \n","        self.encoder = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","    \n","    def forward(self, input, hidden):\n","        input = self.encoder(input.view(1, -1))\n","        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n","        output = self.decoder(output.view(1, -1))\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        return Variable(to_gpu(torch.zeros(self.n_layers, 1, self.hidden_size)))\n","      \n","      \n","      \n","# Turn string into list of longs\n","def char_tensor(string):\n","    tensor = torch.zeros(len(string)).long()\n","    for c in range(len(string)):\n","        tensor[c] = all_characters.index(string[c])\n","    return Variable(to_gpu(tensor))\n","\n","# print(char_tensor('ala ma kota'))      \n","\n","def random_training_set():    \n","    chunk = random_chunk()\n","    inp = char_tensor(chunk[:-1])\n","    target = char_tensor(chunk[1:])\n","    return inp, target\n","  \n","  \n","def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n","    hidden = decoder.init_hidden()\n","    prime_input = char_tensor(prime_str)\n","    predicted = prime_str\n","\n","    # Use priming string to \"build up\" hidden state\n","    for p in range(len(prime_str) - 1):\n","        _, hidden = decoder(prime_input[p], hidden)\n","    inp = prime_input[-1]\n","    \n","    for p in range(predict_len):\n","        output, hidden = decoder(inp, hidden)\n","        \n","        # Sample from the network as a multinomial distribution\n","        output_dist = output.data.view(-1).div(temperature).exp()\n","        top_i = torch.multinomial(output_dist, 1)[0]\n","        \n","        # Add predicted character to string and use as next input\n","        predicted_char = all_characters[top_i]\n","        predicted += predicted_char\n","        inp = char_tensor(predicted_char)\n","\n","    return predicted\n","  \n","  \n","  \n","import time, math\n","\n","def time_since(since):\n","    s = time.time() - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","  \n","  \n","  \n","def train(inp, target):\n","    hidden = decoder.init_hidden()\n","    decoder.zero_grad()\n","    loss = 0\n","\n","    for c in tqdm(range(chunk_len)):\n","        output, hidden = decoder(inp[c], hidden)\n","        loss += criterion(output, target[c])\n","\n","    loss.cuda()\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.data[0] / chunk_len\n","  \n","  \n","  \n","from tqdm import tqdm"],"execution_count":1,"outputs":[{"output_type":"stream","text":["USE_GPU=True\n","file_len = 655594\n","zwiadek, gdy się broni od komarów! -\n","On trzepie swoje, - no więc - dosyć już tych swarówi\n","Znam twoję moc i chcę się tobie wyspowiadać,\n","Będę ci o przeszłości i przyszłości gadać. -\n","A wiesz ty, co o tobi\n","0.19277 GB\n"],"name":"stdout"}]},{"metadata":{"id":"lZY0fPgEXM5h","colab_type":"text"},"cell_type":"markdown","source":["# Training"]},{"metadata":{"id":"ILThkaRPXM5k","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":442},"outputId":"581117e1-8199-4e07-9e04-701d3e10f456","executionInfo":{"status":"ok","timestamp":1524491384133,"user_tz":-120,"elapsed":38329,"user":{"displayName":"Wojtek Czarnowski","photoUrl":"//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg","userId":"115130698336476923651"}}},"cell_type":"code","source":["USE_GPU = True\n","n_epochs = 2  # 2000\n","print_every = 1  # 100\n","plot_every = 10\n","hidden_size = 7000 # 100, 1000\n","n_layers = 1 # 1, 4\n","lr = 0.005\n","\n","print_memsize()\n","\n","decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n","if USE_GPU:\n","  decoder.cuda()\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss()\n","if USE_GPU:\n","  criterion.cuda()\n","\n","start = time.time()\n","all_losses = []\n","loss_avg = 0\n","\n","print_memsize()\n","\n","# with torch.autograd.profiler.profile() as prof:\n","\n","for epoch in tqdm(range(1, n_epochs + 1)):\n","    loss = train(*random_training_set())       \n","    loss_avg += loss\n","\n","    if epoch % print_every == 0:\n","        print('\\n[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","#         print(evaluate('Wh', 200), '\\n')\n","\n","    if epoch % plot_every == 0:\n","        all_losses.append(loss_avg / plot_every)\n","        loss_avg = 0\n","    \n","    print_memsize()\n","\n","# print(prof)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["3.5013 GB\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/2 [00:00<?, ?it/s]\n","  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n"," 29%|██▉       | 58/200 [00:00<00:00, 561.21it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["3.5013 GB\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 51%|█████     | 102/200 [00:00<00:00, 499.07it/s]\u001b[A\n"," 66%|██████▌   | 132/200 [00:00<00:00, 431.87it/s]\u001b[A\n"," 80%|███████▉  | 159/200 [00:00<00:00, 284.64it/s]\u001b[A\n"," 90%|█████████ | 181/200 [00:00<00:00, 238.97it/s]\u001b[A\n","100%|██████████| 200/200 [00:00<00:00, 214.53it/s]\u001b[A\n"," 50%|█████     | 1/2 [00:17<00:17, 17.28s/it]\n","  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n"," 30%|██▉       | 59/200 [00:00<00:00, 582.66it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","[0m 17s (1 50%) 5.1355]\n","3.5013 GB\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 54%|█████▎    | 107/200 [00:00<00:00, 528.91it/s]\u001b[A\n"," 68%|██████▊   | 135/200 [00:00<00:00, 444.60it/s]\u001b[A\n"," 81%|████████  | 162/200 [00:00<00:00, 292.14it/s]\u001b[A\n"," 92%|█████████▎| 185/200 [00:00<00:00, 240.53it/s]\u001b[A\n","100%|██████████| 2/2 [00:34<00:00, 17.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","[0m 34s (2 100%) 11.2898]\n","3.5013 GB\n","3.5013 GB\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"metadata":{"id":"76qUrrsHeQ7b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"e385220b-a3e5-4c64-c207-a02f89bfc4e6","executionInfo":{"status":"ok","timestamp":1524491409500,"user_tz":-120,"elapsed":885,"user":{"displayName":"Wojtek Czarnowski","photoUrl":"//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg","userId":"115130698336476923651"}}},"cell_type":"code","source":["print_memsize()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["3.5013 GB\n"],"name":"stdout"}]},{"metadata":{"id":"3RIoaU0me-Nn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["whos "],"execution_count":0,"outputs":[]},{"metadata":{"id":"NVW5iuPtmexg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":102},"outputId":"3edf0588-e69c-42be-e47f-5a02443a06bf","executionInfo":{"status":"ok","timestamp":1524491433942,"user_tz":-120,"elapsed":635,"user":{"displayName":"Wojtek Czarnowski","photoUrl":"//lh6.googleusercontent.com/-Sx8k456RbyI/AAAAAAAAAAI/AAAAAAAAEVg/Bn2jWaJ_hM0/s50-c-k-no/photo.jpg","userId":"115130698336476923651"}}},"cell_type":"code","source":["print(decoder)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["RNN(\n","  (encoder): Embedding(172, 7000)\n","  (gru): GRU(7000, 7000)\n","  (decoder): Linear(in_features=7000, out_features=172)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"3tR4vMBPmgpm","colab_type":"text"},"cell_type":"markdown","source":["# tmp"]},{"metadata":{"id":"153cTJXDme_A","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"M993ZZuTm9CQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"bnrbsy-imfCN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"1I9lZQ-hnjHT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"kd1s0fGkmfE-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"PqPQ-XC9mfHV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}