{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char-rnn-classification-pl.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1MnuFodDCXwmRCAboH5EhJ0-c6gEHp6L1",
          "timestamp": 1524808584077
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "p8R8cWSlrBRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/eBRPvWB.png)\n",
        "\n",
        "# Klasyfikacja nazwisk z użyciem sieci rekurencyjnych przetwarzających litery\n",
        "\n",
        "Będziemy budować i trenować klasyfikator RNN przetwarzający znaki, aby klasyfikował słowa. Znakowy RNN odczytuje słowa jako serię znaków - wyprowadzając prognozę i \"stan ukryty\" na każdym kroku, wprowadzając swój poprzedni stan ukryty do każdego kolejnego kroku. Końcową prognozę potraktujemy jako wynik, tj. klasę, do należy dane słowo.\n",
        "\n",
        "Mówiąc dokładniej, przeprowadzimy trening sieci na kilku tysiącach nazwisk pochodzących z 18 języków, i będziemy rozpoznawać język z którego nazwisko pochodzi:\n",
        "\n",
        "```\n",
        "> Czarnowski\n",
        "(79.13%) Polish\n",
        "( 6.21%) Russian\n",
        "( 6.04%) Czech\n",
        "\n",
        "> Satoshi\n",
        "(47.51%) Japanese\n",
        "(26.99%) Arabic\n",
        "(10.29%) Polish\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "CVuGznp_rBRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Polecana lektura\n",
        "\n",
        "Zakładam że jest już zainstalowany PyTorch, znasz Python'a, oraz znasz pojęcie Tensor'ów:\n",
        "\n",
        "* http://pytorch.org/ - instalacja PyTorch\n",
        "* [Deep Learning with PyTorch: A 60-minute Blitz](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) - Podstawy PyTorch\n",
        "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) przykłady wykorzystania PyTorch\n",
        "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) jeżeli znasz Lua Torch\n",
        "\n",
        "Trochę wiedzy o RNN:\n",
        "\n",
        "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) przykłady z życia wzięte\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) RNN i LSTM w pigułce"
      ]
    },
    {
      "metadata": {
        "id": "V6C-QlCarBRN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Przygotowanie danych\n",
        "\n",
        "Dane znajdują się w folderze `data/names` są podzielone na 18 plików tekstowych nazwanych wg schematu \"[Language].txt\". Każdy plik zawiera wiele nazwisk, po 1 w każdej linii w losowej kolejności, w większości zapisanych alfabetem łacińskim.\n",
        "\n",
        "Otrzymamy coś w rodzaju słownika (python dictionary) składającego się z list nazwisk dla każdego z języków, `{language: [names ...]}`. Ogólne zmienne \"category\" oraz \"line\" (dla języka i nazwiska w naszym przypadku) są używane dla zapewnienia przyszłej rozszerzalności."
      ]
    },
    {
      "metadata": {
        "id": "a71GOs1JrBRO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "all_filenames = glob.glob('data/names/*.txt')\n",
        "print(all_filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vKAFyRurBRX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename).read().strip().split('\\n')\n",
        "    return lines\n",
        "\n",
        "for filename in all_filenames:\n",
        "    category = filename.split('/')[-1].split('.')[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "print('n_categories =', n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYmQPq5m-BJZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "all_letters = ''.join(sorted(list(set(''.join([''.join(v) for k,v in category_lines.items()])))))\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "print(f'all_letters = {all_letters}')\n",
        "print(f'n_letters = {n_letters}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEuKRvtfrBRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Teraz mamy \"category_lines\", słownik mapujący każdą kategorię (język) do listy nazwisk. Przechowujemy także \"all_categories\" (po prostu lsitę języków) oraz \"n_categories\" dla przyszłego użytku."
      ]
    },
    {
      "metadata": {
        "id": "kW_eF9IMrBRb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "c = category_lines['Polish']; print(len(c))\n",
        "print(c[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQkKmBA1rBRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Konwersja nazwisk na tensory\n",
        "\n",
        "Teraz jak już wszystkie nazwiska są poukładane, musimy je przekonwertować na tensory.\n",
        "\n",
        "Do reprezentacji pojedynczej litery używamy kodowania 1-z-n (ang. one-hot vector) o rozmiarze <1 x n_letters>. Wektor 1-z-n jest wypełniony zerami za wyjątkiem 1 znajdującej w miejscu przynależnym do pożądanej litery np. `\"b\" = <0 1 0 0 0 ...>`.\n",
        "\n",
        "Aby zbudować słowo łączymy kilka takich wektorów w pojedynczą macierz o wymiarach: `<line_length x 1 x n_letters>`.\n",
        "\n",
        "Dodatkowy wymiar oznaczony 1 jest potrzebny ponieważ PyTorch zakłada że wszystko jest ładowane porcjami (ang. batch) - my tu używamy porcji o rozmiarze równym 1.\n"
      ]
    },
    {
      "metadata": {
        "id": "vRuqxAfdrBRf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letter_to_tensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    letter_index = all_letters.find(letter)\n",
        "    tensor[0][letter_index] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def line_to_tensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        letter_index = all_letters.find(letter)\n",
        "        tensor[li][0][letter_index] = 1\n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmbVgnZRrBRh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(letter_to_tensor('c'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UlM0VMsHrBRk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(line_to_tensor('Jones').size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sKEVhPdqrBRn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Budowa sieci rekurencyjnej\n",
        "\n",
        "Przed zastosowaniem metody autograd, stworzenie RNN w Torchu wiązało się z klonowaniem parametrów warstwy dla kolejnych kroków. Warstwy przechowywały stany ukryte oraz gradienty, które obecnie są całkowicie obsługiwane przez graf. Oznaczna to że możesz zaimplementować RNN w bardzo przystępnej formie podobnie jak zwyczajne wartwy feed-forward.\n",
        "\n",
        "Ten moduł RNN (zainspirowany [the PyTorch for Torch users tutorial](https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net)) to tylko 2 linearne warstwy, które operują na wejściu oraz stanie ukrytym, a także aplikują warstwę LogSoftmax na wyjściu.\n",
        "\n",
        "![](https://i.imgur.com/Z2xbySO.png)"
      ]
    },
    {
      "metadata": {
        "id": "-H_F5WHwrBRo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oO72znMkrBRq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ręczne testowanie sieci\n",
        "\n",
        "Mając zdefiniowaną naszą klasę `RNN`, stwórzmy jej nową instancję:"
      ]
    },
    {
      "metadata": {
        "id": "5CbBFv3LrBRq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n",
        "print(rnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5D65D12rBRr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aby uruchomić jakiś krok naszej sieci, musimy najpierw przekazać jakieś dane wejściowe (w tym przypadku Tensor bieżącej litery) oraz poprzedni stan ukryty (który inicjalizujemy na początku zerami). W taki sposób otrzymamy wynik (prawdopodobieństwo każdego języka) oraz następny stan ukryty (niezbędny w kolejnym kroku).\n",
        "\n",
        "Pamiętaj że moduły PyTorch operują na Zmiennych (Variables), a nie bezpośrednio na Tensorach.\n"
      ]
    },
    {
      "metadata": {
        "id": "0VztWCSkrBRs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "input = Variable(letter_to_tensor('A'))\n",
        "hidden = rnn.init_hidden()\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)\n",
        "print('output.size =', output.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7V3WjmyyrBRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Na potrzeby wydajności nie chcemy tworzyć nowego Tensora dla każdego kroku, więc używamy metody `line_to_tensor` zamiast `letter_to_tensor` a także tzw. wycinków (slices). Można to jeszcze zoptymalizować obliczając wcześniej porcje (batches) Tensorów."
      ]
    },
    {
      "metadata": {
        "id": "e225Ggi8rBRu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "input = Variable(line_to_tensor('Albert'))\n",
        "hidden = Variable(torch.zeros(1, n_hidden))\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_m-H2UxrBRw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tak jak widać wynikiem jest Tensor `<1 x n_categories>`, gdzie każdy element jest prawdopodobieństwem danej kategorii."
      ]
    },
    {
      "metadata": {
        "id": "7YnU8U1vrBRw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Przygotowanie do treningu sieci\n",
        "\n",
        "Zanim rozpoczeniemy trening musimy zaimplementować kilka funkcji pomocniczych.\n",
        "Pierwsza to interpreter wyjść naszej sieci. Użyjemy tu `Tensor.topk` aby uzyskać indeks największej wartości:"
      ]
    },
    {
      "metadata": {
        "id": "Hwu8mcP7rBRx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def category_from_output(output):\n",
        "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
        "    category_i = top_i[0][0]\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(category_from_output(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vMB6vperBRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Potrzebna będzie także metoda otrzymywania przykładów treningowych (nazwisko oraz język):\n"
      ]
    },
    {
      "metadata": {
        "id": "yrRTTzbyrBRz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_training_pair():                                                                                                               \n",
        "    category = random.choice(all_categories)\n",
        "    line = random.choice(category_lines[category])\n",
        "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
        "    line_tensor = Variable(line_to_tensor(line))\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = random_training_pair()\n",
        "    print('category =', category, '/ line =', line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOyloI9erBR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Trening sieci\n",
        "\n",
        "Aby wytrenować sieć musimy jej \"pokazać\" wiele przykładów, pozwolić jej zgadywać i powiedzieć jej, kiedy się myli.\n",
        "\n",
        "Na funkcję straty nadaje się metoda: [`nn.NLLLoss`](http://pytorch.org/docs/nn.html#nllloss), ponieważ ostatnia wartwa RNN to `nn.LogSoftmax`."
      ]
    },
    {
      "metadata": {
        "id": "8A9iRTXNrBR1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "in9q2gr8rBR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dodatkowo tworzymy 'optimizer', który będzie aktualizował parametry naszego modelu zależnie od gradientów. Wykorzystujemy tu zwykły algorytm SGD z małym tempem uczenia."
      ]
    },
    {
      "metadata": {
        "id": "2lhQHB5-rBR2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXH_ipl2rBR4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "W każdej pętli treningu:\n",
        "\n",
        "* Tworzymy wejściowe i oczekiwane tensory\n",
        "* Tworzymy zerowy stan wejściowy\n",
        "* Odczytujemy każdą literę\n",
        "    * przechowujemy stan ukryty dla następnej litery\n",
        "* Porównujemy otrzymany wynik z wartością oczekiwaną\n",
        "* Robimy wsteczną propagację\n",
        "* Zwracamy wynik i stratę"
      ]
    },
    {
      "metadata": {
        "id": "CkoFAE12rBR4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(category_tensor, line_tensor):\n",
        "    rnn.zero_grad()\n",
        "    hidden = rnn.init_hidden()\n",
        "    \n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vtXC_N6rBR5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Teraz wystarczy to powtórzyć dla wielu próbek. Skoro funkcja `train` zwraca wynik i stratę można wypisać jej predykcje i śledzić wartości straty. Ponieważ mamy tysiące próbek wyświetlamy wyniki tylko co `print_every` kroków i liczymy średnią stratę.\n"
      ]
    },
    {
      "metadata": {
        "id": "BYBA0bxYrBR6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_epochs = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # Get a random training input and target\n",
        "    category, line, category_tensor, line_tensor = random_training_pair()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "    \n",
        "    # Print epoch number, loss, name and guess\n",
        "    if epoch % print_every == 0:\n",
        "        guess, guess_i = category_from_output(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (epoch, epoch / n_epochs * 100, time_since(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-KyWZH7rBR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kreślenie wyników\n",
        "\n",
        "Kreślenie historii straty z funkcji `all_losses` pokazuje przebieg uczenia sieci:"
      ]
    },
    {
      "metadata": {
        "id": "_nEE9-iyrBR7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.style\n",
        "import matplotlib as mpl\n",
        "mpl.style.use('seaborn')\n",
        "\n",
        "fig=plt.figure()\n",
        "aaa = plt.plot(all_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKYxf_5FYVcd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y = all_losses\n",
        "n = 10\n",
        "averages = []\n",
        "for i in range(len(y) - n):\n",
        "    window = y[i:i+n]\n",
        "    avg = sum(window) / n\n",
        "    # print(window, avg)\n",
        "    averages.append(avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xY5cCyaxYVj8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(all_losses), len(averages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSKtEbz4YVmd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fig=plt.figure()\n",
        "plt.plot(averages);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3m-_xnWrBR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ocenianie wyników\n",
        "\n",
        "Aby sprawdzić jak dobrze sieć radzi sobie z różnymi kategoriami tworzymy tablicę pomyłek, w której dla każdego języka (wiersz) pokazane są wyniki predykcji (kolumny). Aby wyliczyć tablicę pomyłek przepuszczamy serię próbek przez sieć funkcją  `evaluate()`,  która robie to samo co  `train()` za wyjątkiem wstecznej propagacji."
      ]
    },
    {
      "metadata": {
        "id": "nqJksaTmrBR-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Keep track of correct guesses in a confusion matrix\n",
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_confusion = 10000\n",
        "\n",
        "# Just return an output given a line\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "    \n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Go through a bunch of examples and record which are correctly guessed\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = random_training_pair()\n",
        "    output = evaluate(line_tensor)\n",
        "    guess, guess_i = category_from_output(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "    \n",
        "# Normalize by dividing every row by its sum\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_Xi2OlygdrL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mpl.style.use('default')\n",
        "mpl.style.use('seaborn-ticks')\n",
        "\n",
        "mpl.pyplot.set_cmap('hot_r')\n",
        "\n",
        "# Set up plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Set up axes\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "\n",
        "# Force label at every tick\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0cYQCsRrBR_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wybierz widoczne kwadraciki poza główną przekątną aby zobaczyć, które przewidywania nie są prawidłowe, np. chiński zamiast koreańskiego czy hiszpański zamiast włoskiego. Widać, że klasyfikuje dobrze grecki, a słabo angielski (prawdopodobnie z powodu nakładania się z innymi językami).\n"
      ]
    },
    {
      "metadata": {
        "id": "n4Q4jXBOrBSA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Klasyfikacja podanych nazwisk"
      ]
    },
    {
      "metadata": {
        "id": "TgYOUqrjrBSA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "    output = evaluate(Variable(line_to_tensor(input_line)))\n",
        "\n",
        "    # Get top N categories\n",
        "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i]\n",
        "        category_index = topi[0][i]\n",
        "        pred = np.exp(value)\n",
        "        print('(%.2f%%) %s' % (pred*100, all_categories[category_index]))\n",
        "        # print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "        predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')\n",
        "predict('Czarnowski')\n",
        "predict('Kazimierczak')\n",
        "predict('Wołk')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6kOTILyrBSC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ćwiczenia\n",
        "\n",
        "* Wypróbuj inny zbiór danych typu linia -> kategoria, np.:\n",
        "    * słowo -> język\n",
        "    * imię -> płeć\n",
        "    * bohater -> pisarz\n",
        "   \n",
        "* Popraw wyniki tworząc większą sieć i/lub sieć o lepszej strukturze\n",
        "    * Więcej linearnych warstw\n",
        "    * Wypróbuj warstwy `nn.LSTM` oraz `nn.GRU` \n",
        "    * Połącz wiele takich sieci RNN w sieć wyższego rzędu"
      ]
    },
    {
      "metadata": {
        "id": "ZDA3v0tFrBSC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}